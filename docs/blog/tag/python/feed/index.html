<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>python &#8211; Parerga und Paralipomena</title>
	<atom:link href="http://www.michelepasin.org/blog/tag/python/feed/" rel="self" type="application/rss+xml" />
	<link>http://www.michelepasin.org/blog</link>
	<description>At the core of all well-founded belief lies belief that is unfounded - Wittgenstein</description>
	<lastBuildDate>Thu, 06 Aug 2020 10:18:31 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.11</generator>
<site xmlns="com-wordpress:feed-additions:1">13825966</site>	<item>
		<title>More Jupyter notebooks: pyvis and networkx</title>
		<link>http://www.michelepasin.org/blog/2020/08/06/more-jupyter-notebooks-pyvis-and-networkx/</link>
				<pubDate>Thu, 06 Aug 2020 09:55:12 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Data science]]></category>
		<category><![CDATA[graph]]></category>
		<category><![CDATA[jupyter]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[visualization]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3368</guid>
				<description><![CDATA[Lately I&#8217;ve been spending more time creating Jupyter notebooks that demonstrate how to use the Dimensions API for research analytics. In this post I&#8217;ll talk a little bit about two cool Python technologies I&#8217;ve discovered for working with graph data: pyvis and networkx. pyvis and networkx The networkx and pyvis libraries are used for generating and visualizing network [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Lately I&#8217;ve been spending more time creating Jupyter notebooks that demonstrate how to use the <a href="https://api-lab.dimensions.ai/">Dimensions API for research analytics.</a> In this post I&#8217;ll talk a little bit about two cool Python technologies I&#8217;ve discovered for working with graph data: pyvis and networkx.</p>
<h3>pyvis and networkx</h3>
<p>The <a class="reference external" href="https://networkx.github.io/documentation/stable/reference/introduction.html" target="_blank" rel="noopener noreferrer">networkx</a> and <a class="reference external" href="https://pyvis.readthedocs.io/en/latest/tutorial.html" target="_blank" rel="noopener noreferrer">pyvis</a> libraries are used for <em>generating</em> and <em>visualizing</em> network data, respectively.</p>
<p>Pyvis is fundamentally a python wrapper around the popular <a href="https://visjs.github.io/vis-network/examples/">Javascript visJS library.</a> Networkx instead of is a pretty sophisticated package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.</p>
<pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyvis.network</span> <span class="k">import</span> <span class="n">Network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx
</span># generate generic <span class="nn">network graph instance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.Graph()</span><span class="p">
</span># add some nodes and edges
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'Number 1'</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">'group'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'I belong to a different group!'</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">'group'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'couple'</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'couple'</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nx_graph</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'lonely'</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'lonely node'</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp"># instantiatet <span class="nn">pyvis network</span>
&gt;&gt;&gt; </span><span class="n">nt</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="s2">"500px"</span><span class="p">,</span> <span class="s2">"500px"</span><span class="p">)</span>
<span class="go"># populates <span class="gp"><span class="nn">pyvis network from networkx instance</span></span></span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nt</span><span class="o">.</span><span class="n">from_nx</span><span class="p">(</span><span class="n">nx_graph</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"nx.html"</span><span class="p">)</span></pre>
<p>It took me a little to familiarise with the libraries&#8217; concepts and to generate some basic graphs. So, the tutorials linked below are meant to provide some reusable <em>code</em> building blocks for working with these tools.</p>
<p>Once you get the hang of it though, the fun part begins. What are the best data variables to represent in the graph? What color coding strategy is making it easier to explore the data? How many nodes/edges to display? Can we add some interactivity to the visualizations? Check out the resulting visualizations below for more ideas.</p>
<h3>Dataviz: concepts co-occurence network</h3>
<p>The <a href="https://api-lab.dimensions.ai/cookbooks/2-publications/Concepts-network-graph.html">Building a concepts co-occurence network</a> notebook shows how to turn document keywords extracted from &#8216;semantic web&#8217; publications into a simple topic map &#8211; by virtue of their co-occurrence within the same documents.</p>
<p>See also the standalone html version of the interactive visualization: <a href="http://api-sample-data.dimensions.ai/dataviz-exports/concets-cooccurence/concepts_network_2020-08-05.html">concepts_network_2020-08-05.html</a></p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2.jpg"><img class="aligncenter size-large wp-image-3426" src="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2-1024x513.jpg" alt="graph2" width="1024" height="513" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2-1024x513.jpg 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2-300x150.jpg 300w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2-768x385.jpg 768w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph2.jpg 1421w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>&nbsp;</p>
<h3>Dataviz: Organizations Collaboration Network</h3>
<p>The <a href="https://api-lab.dimensions.ai/cookbooks/8-organizations/3-Organizations-Collaboration-Network.html">Building an Organizations Collaboration Network Diagram</a> notebook shows how to use publications&#8217; authors and <a href="https://grid.ac/">GRID</a> data to generate a network of collaborating research organizations.</p>
<p>See also the standalone html version of the interactive visualization: <a href="http://api-sample-data.dimensions.ai/dataviz-exports/3-Organizations-Collaboration-Network/network_2_levels_grid.412125.1.html">network_2_levels_grid.412125.1.html</a></p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1.jpg"><img class="aligncenter size-large wp-image-3424" src="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1-1024x515.jpg" alt="graph1" width="1024" height="515" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1-1024x515.jpg 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1-300x151.jpg 300w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1-768x386.jpg 768w, http://www.michelepasin.org/blog/wp-content/uploads/2020/08/graph1.jpg 1402w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3368</post-id>	</item>
		<item>
		<title>Pypapers: a bare-bones, command line,  PDF manager</title>
		<link>http://www.michelepasin.org/blog/2019/06/30/pypapers-a-bare-bones-command-line-pdf-manager/</link>
				<pubDate>Sun, 30 Jun 2019 22:48:40 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Cultural Informatics]]></category>
		<category><![CDATA[TechLife]]></category>
		<category><![CDATA[paper]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[reference_manager]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3357</guid>
				<description><![CDATA[Ever felt like softwares like Mendeley or Papers are great, but somehow slow you down? Ever felt like none of the many reference manager softwares out there will ever cut it for you, cause you need something R E A L L Y SIMPLE? I did. Many times. So I&#8217;ve finally crossed the line and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Ever felt like softwares like <a href="https://www.mendeley.com/homepage-2-1?interaction_required=true&#038;mboxSession=ea3c06ad39f14ce29d625b9d3be138c5">Mendeley</a> or <a href="https://www.papersapp.com/">Papers</a> are great, but somehow slow you down? Ever felt like none of the many <a href="https://en.wikipedia.org/wiki/Comparison_of_reference_management_software">reference manager softwares</a> out there will ever cut it for you, cause you need something R E A L L Y SIMPLE? I did. Many times. So I&#8217;ve finally crossed the line and tried out building a simple commmand-line PDF manager. <a href="https://github.com/lambdamusic/pypapers">PyPapers</a>, is called.</p>
<p>Yes &#8211; that&#8217;s right &#8211; <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">command line</a>. So not for everyone. Also: this is bare bones and pre-alpha. So don&#8217;t expect wonders. It basically provides a simple interface for searching a folder full of PDFs. That&#8217;s all for now!</p>
<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/o74Ct1EwZwI?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe>
<p>   </p>
<h3>Key features (or lack of)</h3>
<li><strong>Mac only, I&#8217;m afraid.</strong> I&#8217;m sitting on the shoulders of a giant. That is, <a href="https://ss64.com/osx/mdfind.html">mdfind</a>.</li>
<li>No fuss <strong>search in file names</strong> only or <strong>full text</strong></li>
<li>Shows all results and relies on <a href="https://support.apple.com/en-gb/guide/preview/welcome/mac">Preview</a> for reading</li>
<li><strong>Highlighting</strong> on Preview works pretty damn fine and it&#8217;s the ultimate compatibility solution (any other software kinds of locks you in eventually, imho)</li>
<li><strong>Open source</strong>. If you can code Python you can customise it to your needs. If you can&#8217;t, open an <a href="https://github.com/lambdamusic/pypapers/issues">issue in github</a> and I may end up doing it.</li>
<li>It recognises <strong>sub-folders</strong>, so that can be leveraged to become a simple, filesystem level, categorization structure for your PDFs (eg I have different folders for articles, books, news etc..)</li>
<li>Your PDFs live in the Mac <strong>filesystem</strong> ultimately. So you can always search them using Finder in case you get bored of the command line.</li>
<h3>First impressions</h3>
<p>Pretty good. Was concerned I was gonna miss things like collections or tags. But I found a workaround: first, identify the papers I am interested in. Then, create a folder in the same directory and symlink them in there (= create an <a href="https://kb.iu.edu/d/achy">alias</a>).</p>
<p>It&#8217;s not quite like <a href="https://www.taoistic.com/taoquotes/taoquotes-12-simplicity-stillness-silence.htm">uncarved wood,</a> but it definitely feels simple enough.</p>
<p> </p>
<p>   </p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3357</post-id>	</item>
		<item>
		<title>Introducing DimCli: a Python CLI for the Dimensions API</title>
		<link>http://www.michelepasin.org/blog/2019/05/24/introducing-dimcli-a-python-cli-for-dimensions-api/</link>
				<pubDate>Fri, 24 May 2019 11:10:15 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Data science]]></category>
		<category><![CDATA[TechLife]]></category>
		<category><![CDATA[api]]></category>
		<category><![CDATA[cli]]></category>
		<category><![CDATA[dimensions]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[scholarly analytics]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3322</guid>
				<description><![CDATA[For the last couple of months I&#8217;ve been working on a new open source Python project. This is called DimCli  and it&#8217;s a library aimed at making it simpler to work with the Dimensions Analytics API. The project is available on Github. In a nutshell, DimCli helps people becoming productive with the powerful scholarly analytics API [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>For the last couple of months I&#8217;ve been working on a new open source Python project. This is called <strong>DimCli</strong>  and it&#8217;s a library aimed at making it simpler to work with the Dimensions Analytics API.</p>
<p>The project is <a href="https://github.com/lambdamusic/dimcli">available on Github</a>. In a nutshell, DimCli helps people becoming productive with the powerful scholarly analytics API from Dimensions. See the video below for a quick taster of the functionalities available.</p>
<div>
<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/HbZPxJ7G_00?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe>
</div>
<h3>Background</h3>
<p>I recenlty joined the <a href="https://www.dimensions.ai/">Dimensions</a> team, so needed a way to get to grips with their feature-rich API (<a href="https://docs.dimensions.ai/dsl">official docs</a>). So, building DimCli has been a fun way for me to dig into the logic of the <strong>Dimensions Search Language</strong> (DSL).</p>
<p>Plus, this project gave me a chance to learn more about two awesome Python technologies: <a href="https://github.com/jupyterlab/jupyterlab">JupyterLab</a> and its magic commands, as well as the <a href="https://python-prompt-toolkit.readthedocs.io/en/stable/">Python Prompt Toolkit</a> library.</p>
<p><img class="aligncenter size-full wp-image-3339" src="https://i1.wp.com/www.michelepasin.org/blog/wp-content/uploads/2019/05/Screenshot-2019-05-24-at-12.16.47.png?w=1102" alt="Screenshot 2019-05-24 at 12.16.47.png" width="551" height="166" /></p>
<h3>Features</h3>
<p>In a nutshell, this is what DimCli has to offer:</p>
<li>It&#8217;s an <strong>interactive</strong> <strong>query console</strong> for the Dimensions Analytics API (ps: <a href="https://www.dimensions.ai/">Dimensions</a> is a world-class research-data platform including information about millions of documents like publications, patents, grants, clinical trials and policy documents.</li>
<li>It <strong>helps</strong> <strong>learning the Dimensions Search Language (DSL)</strong> thanks to a built-in autocomplete and documentation search mechanism.</li>
<li>It handles <strong>authentication</strong> transparently either via a global user-specific credentials file, or by passing credentials manually (e.g. when used within shared environments).</li>
<li>It allows to <strong>export results to CSV, JSON and pandas dataframes</strong>, hence making it easier to integrate with other data analysis tools.</li>
<li>It is <strong>compatible with Jupyter</strong>, e.g. it includes various magic commands that make it super simple to interrogate Dimensions (<a href="https://github.com/digital-science/dimensions-api/tree/master/1.Getting%20Started">various examples here</a>).</li>
<h3>Feedback</h3>
<p>DimCli lives on <a href="https://github.com/lambdamusic/dimcli">Github</a>, so for any feedback or bug reports, feel free to open an issue there.</p>
<p><img class="aligncenter  wp-image-3338" src="https://i2.wp.com/www.michelepasin.org/blog/wp-content/uploads/2019/05/Screenshot-2019-05-23-at-18.06.32.png?w=1126" alt="Screenshot 2019-05-23 at 18.06.32.png" width="444" height="282" /></p>
<p> </p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3322</post-id>	</item>
		<item>
		<title>Ontospy 1.9.8 released</title>
		<link>http://www.michelepasin.org/blog/2019/01/03/ontospy-1-9-8-released/</link>
				<pubDate>Thu, 03 Jan 2019 11:55:14 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[ontospy]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[rdf]]></category>
		<category><![CDATA[semantic web]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3279</guid>
				<description><![CDATA[Ontospy version 1.9.8 has been just released and it contains tons of improvements and new features. Ontospy is a lightweight open-source Python library and command line tool for working with vocabularies encoded in the RDF family of languages. Over the past month I&#8217;ve been working on a new version of Ontospy, which is now available for download [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Ontospy version 1.9.8 has been just released and it contains tons of improvements and new features. <a href="http://lambdamusic.github.io/Ontospy/">Ontospy</a> is a lightweight open-source Python library and command line tool for working with vocabularies encoded in the <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a> family of languages.</p>
<p>Over the past month I&#8217;ve been working on a new version of Ontospy, which is now available for download on <a href="https://pypi.org/project/ontospy/">Pypi</a>.</p>
<iframe class='youtube-player' type='text/html' width='560' height='315' src='https://www.youtube.com/embed/MkKrtVHi_Ks?version=3&#038;rel=1&#038;fs=1&#038;autohide=2&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;wmode=transparent' allowfullscreen='true' style='border:0;'></iframe>
<p> &nbsp;</p>
<h3>What&#8217;s new in this version</h3>
<li>The library to generate <strong>ontology documentation</strong> (as html or markdown) is now included within the main Ontospy distribution. Previously this library was distributed separately under the name <code style="display: inline; padding: 0px;">ontodocs</code>.  The main problem with this approach is that keeping the two projects in sync was becoming too time-consuming for me, so I&#8217;ve decided to merge them. NOTE one can still choose whether or not to include this extra library <a href="http://lambdamusic.github.io/Ontospy/#installation">when installing</a>.</li>
<li>You can print out the <strong>raw RDF data</strong> being returned via command line argument.</li>
<li>One can decided whether or not to include <strong>&#8216;inferred&#8217; schema definitions</strong> extracted from an RDF payload. The inferences are pretty basic for now (eg the object of <code style="display: inline; padding: 0px;">rdf:type</code> statements is taken to be a type) but this allows for example to quickly dereference a DBpedia URI and pull out all types/predicates being used.</li>
<li>The online <strong>documentation</strong> are now hosted on <a href="http://lambdamusic.github.io/Ontospy/">github pages</a> and available within the <code style="display: inline; padding: 0px;">/docs</code> folder of the project.</li>
<li>Improved support for <b>JSON-LD</b> and a new utility for quickly sending JSON-LD data to the <a href="https://json-ld.org/playground/">online playground tool</a>.</li>
<li>Several other bug fixes and improvements, in particular to the <b>interactive</b> ontology exploration mode (<code style="display: inline; padding: 0px;">shell</code> command), the visualization library (<b>new visualizations</b> are available &#8211; albeit still in alpha state).</li>
<p> &nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3279</post-id>	</item>
		<item>
		<title>Ontospy v. 1.6.7</title>
		<link>http://www.michelepasin.org/blog/2016/06/12/ontospy-v-1-6-7/</link>
				<pubDate>Sun, 12 Jun 2016 18:05:51 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[ontology]]></category>
		<category><![CDATA[ontospy]]></category>
		<category><![CDATA[python]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2783</guid>
				<description><![CDATA[A new and improved version of OntoSpy (1.6.7) is available online. OntoSpy is a lightweight Python library and command line tool for inspecting and visualizing vocabularies encoded in the RDF family of languages. This update includes support for Python 3, plus various other improvements that make it easier to query semantic web vocabularies using OntoSpy&#8217;s [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>A new and improved version of <a href="https://github.com/lambdamusic/ontospy">OntoSpy</a> (1.6.7) is available online. OntoSpy is a lightweight Python library and command line tool for inspecting and visualizing vocabularies encoded in the <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a> family of languages.</p>
<p>This update includes support for Python 3, plus various other improvements that make it easier to query semantic web vocabularies using OntoSpy&#8217;s interactive shell module. To find out more about Ontospy:</p>
<li>Docs: <a href="http://ontospy.readthedocs.org">http://ontospy.readthedocs.org</a></li>
<li>CheeseShop: <a href="https://pypi.python.org/pypi/ontospy">https://pypi.python.org/pypi/ontospy</a></li>
<li>Github: <a href="https://github.com/lambdamusic/ontospy">https://github.com/lambdamusic/ontospy</a></li>
<p> <br />
Here&#8217;s a short video showing a typical sessions with the OntoSpy <a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">repl</a>: </p>
<p><iframe src="https://player.vimeo.com/video/169707591" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></p>
<h3>What&#8217;s new in this release</h3>
<p>The main new features of version 1.6.7:<br />
 </p>
<li>added support for Python 3.0 (thanks to a pull request from <a href="https://github.com/T-002">https://github.com/T-002</a>)</li>
<li>the <span style="font-family:monospace;color:#000000; ">import [file | uri | repo | starter-pack]</span> command that makes it easier to load models into the local repository. You can import a local RDF file or a web resource via its URI. The <span style="font-family:monospace;color:#000000; ">repo</span> option allows to select an ontology by listing the one available in a couple of online public repositories; finally the <span style="font-family:monospace;color:#000000; ">starter-pack</span> option can be used to download automatically a few widely used vocabularies (e.g. FOAF,DC etc..) into the local repository &#8211; mostly useful after a fresh installation in order to get started</li>
<li>the <span style="font-family:monospace;color:#000000; ">info [toplayer | parents | children | ancestors | descendants]</span> command allows to print more detailed info about entities</li>
<li>added an incremental search mode based on text patterns e.g. to reduce the options returned by the <span style="font-family:monospace;color:#000000; ">ls</span> command </li>
<li>calling the <span style="font-family:monospace;color:#000000; ">serialize</span> command at ontology level now serializes the whole graph</li>
<li>made the caching functionality version-dependent </li>
<li>added json serialization option (via <a href="https://github.com/RDFLib/rdflib-jsonld">rdflib-jsonld</a>)</li>
<p> </p>
<p>Install/update simply by typing <span style="font-family:monospace;color:#000000; ">pip install ontospy -U</span> in your terminal window (see this <a href="http://ontospy.readthedocs.io/en/latest/installation.html">page</a> for more info).</p>
<h3>Coming up next</h3>
<p>I&#8217;d really like to add more output visualisations e.g. <a href="https://github.com/anvaka/VivaGraphJS">VivaGraphJS</a> or one of the <a href="http://philogb.github.io/jit/demos.html">JavaScript InfoVis Toolkit</a>.</p>
<p>Probably even more interesting, I&#8217;d like to refactor the code generating visualisations so that it allows people to develop their own via a standard API and then publishing them on GitHub. </p>
<p>Lastly, more support for instance management: querying and creating instances from any loaded ontology.</p>
<p>Of course, any comments or suggestions are welcome as usual &#8211;  either using the form below or via <a href="https://github.com/lambdamusic/ontospy/issues">GitHub</a>. Cheers!</p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">2783</post-id>	</item>
		<item>
		<title>Accessing OS X dictionary with Python</title>
		<link>http://www.michelepasin.org/blog/2015/11/28/accessing-os-x-dictionary-with-python/</link>
				<pubDate>Sat, 28 Nov 2015 15:57:06 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Just Blogging]]></category>
		<category><![CDATA[TechLife]]></category>
		<category><![CDATA[Tips and Tricks]]></category>
		<category><![CDATA[dictionary]]></category>
		<category><![CDATA[osx]]></category>
		<category><![CDATA[python]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2724</guid>
				<description><![CDATA[A little script that allows to access the OS X Dictionary app using Python. Tip: make the script executable and add an alias for it in order to be able to call it from the command line easily. &#160;]]></description>
								<content:encoded><![CDATA[<p>A little script that allows to access the OS X <a href="https://en.wikipedia.org/wiki/Dictionary_(software)">Dictionary app</a> using Python. </p>
<p>Tip: make the script executable and add an alias for it in order to be able to call it from the command line easily. </p>
<p><script src="https://gist.github.com/lambdamusic/bdd56b25a5f547599f7f.js"></script></p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">2724</post-id>	</item>
		<item>
		<title>Dereference a DOI using python</title>
		<link>http://www.michelepasin.org/blog/2014/12/03/dereference-a-doi-using-python/</link>
				<comments>http://www.michelepasin.org/blog/2014/12/03/dereference-a-doi-using-python/#comments</comments>
				<pubDate>Wed, 03 Dec 2014 16:49:44 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[TechLife]]></category>
		<category><![CDATA[citation]]></category>
		<category><![CDATA[doi]]></category>
		<category><![CDATA[python]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2555</guid>
				<description><![CDATA[A little python script that allows to pass an article DOI in order to obtain all the metadata related to that article. The script relies on the handy crosscite.org API, which is one of the wonderful services provided by CrossRef. &#160;]]></description>
								<content:encoded><![CDATA[<p>A little python script that allows to pass an article <a href="http://en.wikipedia.org/wiki/Digital_object_identifier">DOI</a> in order to obtain all the metadata related to that article.</p>
<p>The script relies on the handy <a href="http://www.crosscite.org/cn/">crosscite.org API</a>, which is one of the wonderful services provided by <a href="http://www.crossref.org/">CrossRef</a>. </p>
<p><script src="https://gist.github.com/lambdamusic/3b1062b1d467fa45a2d0.js"></script></p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2014/12/03/dereference-a-doi-using-python/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">2555</post-id>	</item>
		<item>
		<title>Teaching programming concepts visually with the Online Python Tutor</title>
		<link>http://www.michelepasin.org/blog/2012/10/12/teaching-programming-concepts-visually-with-the-online-python-tutor/</link>
				<comments>http://www.michelepasin.org/blog/2012/10/12/teaching-programming-concepts-visually-with-the-online-python-tutor/#comments</comments>
				<pubDate>Fri, 12 Oct 2012 08:52:49 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Just Blogging]]></category>
		<category><![CDATA[learning]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[teaching]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2208</guid>
				<description><![CDATA[The Online Python Tutor is a Web-based program visualization for CS education, developed in collaboration with Google. It provides an easy-to-use online environment for writing code and testing it interactively. A great resource for teaching computer science concepts! As part of his CS education work at Google, Philip Guo has been developing an open-source educational [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>The Online Python Tutor is a Web-based program visualization for CS education, developed in collaboration with Google. It provides an easy-to-use online environment for writing code and testing it interactively. A great resource for teaching computer science concepts!  </p>
<blockquote><p>As part of his CS education work at <a href="http://research.google.com/index.html">Google</a>, <a href="https://plus.google.com/117790530324740296539/posts/f2XggMgZtaQ">Philip Guo</a> has been developing an open-source educational tool called <a href="http://www.pythontutor.com/">Online Python Tutor</a>. This tool enables teachers and students to write Python programs directly in the web browser and then single-step forwards and backwards to visualize what the computer is doing as it executes those programs. The tool has already been used by over 100,000 people but has a lot of potential for advancement. Philip is actively seeking partnerships with educators at all grade levels to deploy and <a href="https://github.com/pgbovine/OnlinePythonTutor/blob/master/v3/docs/project-ideas.md">improve</a> the Online Python Tutor tool. Visit the <a href="http://www.pythontutor.com/">URL</a> for more information on using the tool and how to get involved.</p></blockquote>
<h3>Create, Test, Share</h3>
<p>Once you&#8217;ve created a program, you can also share it online via a url, or get a snippet of code that will let you embed it in your site. Which is pretty neat! For example: </p>
<p><iframe width="800" height="500" frameborder="0" src="http://pythontutor.com/iframe-embed.html#code=def+factorial(n)%3A%0A++++if+n+%3D%3D+1%3A%0A++++++++return+1%0A++++else%3A%0A++++++++return+n+*+(factorial(n-1))%0A%0Aprint+factorial(5)&#038;cumulative=false&#038;py=2&#038;curInstr=0"> </iframe></p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2012/10/12/teaching-programming-concepts-visually-with-the-online-python-tutor/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">2208</post-id>	</item>
		<item>
		<title>Getting hold of your Flickr collections with Python</title>
		<link>http://www.michelepasin.org/blog/2012/05/07/getting-hold-of-your-flickr-collections-with-python/</link>
				<pubDate>Mon, 07 May 2012 12:11:52 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Tips and Tricks]]></category>
		<category><![CDATA[api]]></category>
		<category><![CDATA[flickr]]></category>
		<category><![CDATA[python]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=1889</guid>
				<description><![CDATA[Recently I&#8217;ve been a little disappointed with Flickr, the popular online photo-sharing service. Photos gone missing, entire albums disappeared. Not really what you&#8217;d like to happen to your photo collection, especially when it&#8217;s very large and therefore it&#8217;s difficult to be always on top of what&#8217;s there and what&#8217;s not.. Time to change strategy: use [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Recently I&#8217;ve been a little disappointed with <a href="http://www.flickr.com/">Flickr</a>, the popular online photo-sharing service. Photos gone missing, entire albums disappeared. Not really what you&#8217;d like to happen to your photo collection, especially when it&#8217;s very large and therefore it&#8217;s difficult to be always on top of what&#8217;s there and what&#8217;s not.. Time to change strategy: use flickr for sharing and my local HD for backup! </p>
<p>I emailed the customer service people at Flickr, they promptly replied that it wasn&#8217;t their fault but most likely a bug with other apps I had previously authorised to edit my Flickr collection (e.g. iPhoto or Aperture). Bad news: apparently whatever happened now what&#8217;s lost is lost forever. Not much to my consolation, the same happened to other people, for example check this <a href="http://amateurtraveler.com/2010/03/27/photos-disappearing-from-flickr-when-the-cloud-fails/">post</a> or this <a href="http://thomashawk.com/2007/03/flickr-users-photos-disappearing-from.html">post</a> to see alternative versions of the problem from 2010 and 2007. </p>
<p>So I&#8217;ve suddenly realised the cloud isn&#8217;t that secure a place, as yet. It&#8217;s time to change strategy: use flickr for sharing and my local HD for backup! </p>
<p>The good news is that if you know a little programming you can download your entire Flickr collection without having to pay a cent, for example by using Python. There are a few free libraries out there for accessing the <a href="http://www.flickr.com/services/api/">Flickr API</a>s, such as <a href="http://halotis.com/2009/09/08/download-images-from-flickr-with-python/">flickrpy</a> and <a href="http://stuvel.eu/media/flickrapi-docs/documentation/">FlickrAPI</a>. They both require you to fiddle a little with the code (at the very least, get a personalised passkey from Flickr and add it to the python program) in order to get what you want. </p>
<p>The one I&#8217;ve gone for instead is a little package called <a href="https://github.com/dan/hivelogic-flickrtouchr">flickrtouchr</a>, which is even easier to use. After downloading you just have to run it from the command line and it&#8217;ll begin browsing your whole Flickr collection and download pictures at the highest resolution available. I have more than 8000 photos, and it worked like a charm  &#8211; beware though &#8211;  it took more than 10 hours on my TalkTalk connection. </p>
<p>Thanks Dan@<a href="http://hivelogic.com/">hivelogic.com</a> for writing this code &#8211; couldn&#8217;t be asking for more!</p>
<pre style='color:#d1d1d1;background:#000000; overflow:auto; font-size:12px;'><span style='color:#d2cd86; '>[</span>mac<span style='color:#d2cd86; '>]</span>@mike<span style='color:#d2cd86; '>:</span><span style='color:#d2cd86; '>~</span><span style='color:#d2cd86; '>/</span>Dropbox<span style='color:#d2cd86; '>/</span>code<span style='color:#d2cd86; '>/</span>python<span style='color:#d2cd86; '>/</span>_libs<span style='color:#d2cd86; '>/</span>dan<span style='color:#d2cd86; '>-</span>hivelogic<span style='color:#d2cd86; '>-</span>flickrtouchr<span style='color:#d2cd86; '>-</span>9ba645b<span style='color:#d2cd86; '>></span>python flickrtouchr<span style='color:#d2cd86; '>.</span>py <span style='color:#d2cd86; '>~</span><span style='color:#d2cd86; '>/</span>Desktop<span style='color:#d2cd86; '>/</span>FlickrBackupFolder

In order to allow FlickrTouchr to read your photos <span style='color:#e66170; font-weight:bold; '>and</span> favourites
you need to allow the application<span style='color:#d2cd86; '>.</span> Please press <span style='color:#e66170; font-weight:bold; '>return</span> when you've
granted access at the following url <span style='color:#d2cd86; '>(</span>which should have opened
automatically<span style='color:#d2cd86; '>)</span><span style='color:#d2cd86; '>.</span>

http<span style='color:#d2cd86; '>:</span><span style='color:#d2cd86; '>/</span><span style='color:#d2cd86; '>/</span>api<span style='color:#d2cd86; '>.</span>flickr<span style='color:#d2cd86; '>.</span>com<span style='color:#d2cd86; '>/</span>services<span style='color:#d2cd86; '>/</span>auth<span style='color:#d2cd86; '>/</span><span style='color:#d2cd86; '>?</span>api_key<span style='color:#d2cd86; '>=</span>e2245325378b5675b4af4e8cdb0564716fa9bd<span style='color:#d2cd86; '>&amp;</span>perms<span style='color:#d2cd86; '>=</span>read<span style='color:#d2cd86; '>&amp;</span>frob<span style='color:#d2cd86; '>=</span>8856734hhgbbhsksd19443<span style='color:#d2cd86; '>-</span>caa77e89367asbbhfa2ba<span style='color:#d2cd86; '>-</span><span style='color:#008c00; '>600258</span><span style='color:#d2cd86; '>&amp;</span>api_sig<span style='color:#d2cd86; '>=</span>a4aasdbbnb345c7fb46bdd33cfa65ec17bb32a

Waiting <span style='color:#e66170; font-weight:bold; '>for</span> you to press <span style='color:#e66170; font-weight:bold; '>return</span>

Egypt <span style='color:#008c00; '>1</span> <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> <span style='color:#e66170; font-weight:bold; '>in</span> set <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> Sharm el Sheik<span style='color:#d2cd86; '>,</span> Dec <span style='color:#008c00; '>2011</span>
Egypt <span style='color:#008c00; '>2</span> <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> <span style='color:#e66170; font-weight:bold; '>in</span> set <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> Sharm el Sheik<span style='color:#d2cd86; '>,</span> Dec <span style='color:#008c00; '>2011</span>
Egypt <span style='color:#008c00; '>3</span> <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> <span style='color:#e66170; font-weight:bold; '>in</span> set <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> Sharm el Sheik<span style='color:#d2cd86; '>,</span> Dec <span style='color:#008c00; '>2011</span>
Egypt <span style='color:#008c00; '>4</span> <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> <span style='color:#e66170; font-weight:bold; '>in</span> set <span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> Sharm el Sheik<span style='color:#d2cd86; '>,</span> Dec <span style='color:#008c00; '>2011</span>

<span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span><span style='color:#d2cd86; '>.</span> etc…<span style='color:#d2cd86; '>.</span>
</pre>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">1889</post-id>	</item>
		<item>
		<title>Survey of Pythonic tools for RDF and Linked Data programming</title>
		<link>http://www.michelepasin.org/blog/2011/02/24/survey-of-pythonic-tools-for-rdf-and-linked-data-programming/</link>
				<comments>http://www.michelepasin.org/blog/2011/02/24/survey-of-pythonic-tools-for-rdf-and-linked-data-programming/#comments</comments>
				<pubDate>Thu, 24 Feb 2011 15:21:27 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[TechLife]]></category>
		<category><![CDATA[linkeddata]]></category>
		<category><![CDATA[python]]></category>
		<category><![CDATA[rdf]]></category>
		<category><![CDATA[rdflib]]></category>
		<category><![CDATA[semanticweb]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=1110</guid>
				<description><![CDATA[In this post I&#8217;m reporting on a recent survey I made in the context of a Linked Data project I&#8217;m working on, SAILS. The Resource Description Framework (RDF) is a data model and language which is quickly gaining momentum in the open-data and data-integration worlds. In SAILS we&#8217;re developing a prototype for rdf-data manipulation and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>In this post I&#8217;m reporting on a recent survey I made in the context of a <a href="http://en.wikipedia.org/wiki/Linked_Data">Linked Data</a> project I&#8217;m working on, <a href="http://sailsproject.cerch.kcl.ac.uk/">SAILS</a>. The <a href="http://en.wikipedia.org/wiki/Resource_Description_Framework">Resource Description Framework</a> (RDF) is a data model and language which is quickly gaining momentum in the open-data and data-integration worlds. In SAILS we&#8217;re developing a prototype for rdf-data manipulation and querying, but since the final application (of which the rdf-components is part of) will be written in Python and Django, in what follows I tried to gather information about all the existing libraries and frameworks for doing rdf-programming using python. </p>
<h2>1. Python libraries for working with Rdf</h2>
<h3> RdfLib <a style="font-size: 14px;" href="http://www.rdflib.net/">http://www.rdflib.net/</a></h3>
<p>RdfLib (<a href="http://www.rdflib.net/rdflib-3.0.0.tar.gz">download</a>) is a pretty solid and extensive rdf-programming kit for python. It contains parsers and serializers for RDF/XML, N3, NTriples, Turtle, TriX and RDFa. The library presents a Graph interface which can be backed by any one of a number of store implementations, including, memory, MySQL, Redland, SQLite, Sleepycat, ZODB and SQLObject.</p>
<p>The latest release is <strong> RdfLib 3.0</strong>, although I have the feeling that many are still using the previous release, <strong>2.4</strong>. One big difference between the two is that in 3.0 some libraries have been separated into another package (called <a href="http://code.google.com/p/rdfextras/">rdfextras</a>); among these libraries there&#8217;s also the one you need for processing <a href="http://en.wikipedia.org/wiki/SPARQL">sparql</a> queries (the rdf query language), so it&#8217;s likely that you want to install that too.<br />
A short overview of the difference between these two recent releases of RdfLib can be found <a href="http://code.google.com/p/rdflib/wiki/UpgradingToVersion3">here</a>. The APIs documentation for RdfLib 2.4 is available <a href="http://www.rdflib.net/rdflib-2.4.0/html/index.html">here</a>, while the one for RdfLib 3.0 can be found <a href="http://code.alcidesfonseca.com/docs/rdflib/index.html">here</a>. Finally, there are also some other (a bit older, but possibly useful) docs on the <a href="http://code.google.com/p/rdflib/w/list">wiki</a>.</p>
<p>Next thing, you might want to check out these tutorials:</p>
<li><a href="http://semanticweb.org/wiki/Getting_data_from_the_Semantic_Web.html">Getting data from the Semantic Web</a>: a nice example of how to use RdfLib and python in order to get data from  <a href="http://dbpedia.org/">DBPedia</a>, the Semantic Web version of Wikipedia.</li>
<li><a href="http://johngoodwin225.wordpress.com/2011/01/18/how-can-i-use-the-ordnance-survey-linked-data-a-python-rdflib-example/">How can I use the Ordnance Survey Linked Data</a>: shows how to install RdfLib and query the linked data offered by <a href="http://blog.ordnancesurvey.co.uk/2011/01/how-linked-data-can-reap-benefits/">Ordnance Survey</a>.</li>
<li><a href="http://gromgull.net/blog/2011/01/a-quick-and-dirty-guide-to-your-first-time-with-rdf/">A quick and dirty guide to YOUR first time with RDF</a>: another example of querying Uk government data found on <a href="http://data.gov.uk/">data.gov.uk</a> using RdfLib and Berkely/Sleepycat DB.</li>
<h3>RdfAlchemy <a style="font-size: 14px;" href="http://www.openvest.com/trac/wiki/RDFAlchemy">http://www.openvest.com/trac/wiki/RDFAlchemy</a></h3>
<p>The goal of RDFAlchemy (<a href="http://www.openvest.com/trac/wiki/RDFAlchemy#Installation">install</a> | <a href="http://www.openvest.com/public/docs/rdfalchemy/api/">apidocs</a> | <a href="http://groups.google.com/group/rdfalchemy-dev">usergroup</a>) is to allow anyone who uses  python to have a object type API access to an RDF Triplestore. In a nutshell, the same way that <a href="http://www.sqlalchemy.org/">SQLAlchemy</a> is an ORM (Object Relational Mapper) for relational database users, RDFAlchemy is an ORM (Object RDF Mapper) for semantic web users.</p>
<p>RdfAlchemy can also work in conjunction with other datastores, including rdflib, Sesame, and Jena. Support for SPARQL is present, although it seems less stable than the rest of the library.</p>
<h3>Fuxi <a style="font-size: 14px;" href="http://code.google.com/p/fuxi/">http://code.google.com/p/fuxi/</a></h3>
<p>FuXi is a Python-based, bi-directional logical reasoning system for the semantic web. It <strong>requires</strong> rdflib 2.4.1 or 2.4.2 and it is <strong>not</strong> compatible with rdflib 3. FuXi aims to be the &#8216;engine for contemporary expert systems based on the Semantic Web technologies&#8217;. The documentation can be found <a href="http://fuxi.googlecode.com/hg/documentation/html/index.html">here</a>; it might be useful also to look at the <a href="http://code.google.com/p/fuxi/wiki/FuXiUserManual">user-manual</a> and the <a href="http://groups.google.com/group/fuxi-discussion">discussion group</a>.  </p>
<p>In general, it looks as if Fuxi can offer a complete solution for knowledge representation and reasoning over the semantic web; it is quite sophisticated and well documented (partly via several academic articles). The downside is that to the end of hacking together a linked data application.. well Fuxi is probably just too complex and difficult to learn.</p>
<li><a href="http://blog.okfn.org/2010/08/02/about-inferencing/">About Inferencing</a>: a very short introduction to what Fuxi inferencing capabilities can do in the context of an rdf application.</li>
<h3>ORDF <a style="font-size: 14px;" href="http://ordf.org/">ordf.org</a></h3>
<p>ORDF (<a href="http://packages.python.org/ordf/administration.html#installation">download</a> | <a href="http://packages.python.org/ordf/index.html">docs</a>) is the <a href="http://okfn.org/">Open Knowledge Foundation</a>‘s library of support infrastructure for RDF. It is <strong>based</strong> on RDFLib and contains an object-description mapper, support for multiple back-end indices, message passing, revision history and provenance, a namespace library and a variety of helper functions and modules to ease integration with the <a href="http://pylonshq.com/">Pylons</a> framework.</p>
<p>The current version of this library is 0.35. You can have a peek at some of its key functionalities by checking out the &#8216;<a href="http://packages.python.org/ordf/odm.html">Object Description Mapper</a>&#8216; &#8211; an equivalent to what an Object-Relational Mapper would give you in the context of a relational database. The library seems to be pretty solid; for an example of a system built on top of ORDF you can see <a href="http://bibliographica.org/">Bibliographica</a>, an online open catalogue of cultural works.</p>
<li>Why using RDF? The <a href="http://packages.python.org/ordf/design_considerations.html">Design Considerations</a> section in the ORDF documentation discusses the reasons that led to the development of this library in a clear and practical fashion.</li>
<h3>Django-rdf <a style="font-size: 14px;" href="http://code.google.com/p/django-rdf/">http://code.google.com/p/django-rdf/</a></h3>
<p>Django-RDF (<a href="http://code.google.com/p/django-rdf/downloads/list">download</a> | <a href="http://code.google.com/p/django-rdf/wiki/FAQ">faq</a> | <a href="http://groups.google.com/group/django-rdf">discussiongroup</a>) is an RDF engine implemented in a generic, reusable <a href="http://www.djangoproject.com/">Django</a> app, providing complete RDF support to Django projects without requiring any modifications to existing framework or app source code. The philosophy is simple: do your web development using Django just like you&#8217;re used to, then turn the knob and &#8211; with no additional effort &#8211; expose your project on the semantic web.</p>
<p>Django-RDF can expose models from any other app as RDF data. This makes it easy to write new views that return RDF/XML data, and/or query existing models in terms of RDFS or OWL classes and properties using (a variant of) the SPARQL query language. SPARQL in, RDF/XML out &#8211; two basic semantic web necessities. Django-RDF also implements an RDF store using its internal models such as Concept, Predicate, Resource, Statement, Literal, Ontology, Namespace, etc. The SPARQL query engine returns query sets that can freely mix data in the RDF store with data from existing Django models.</p>
<p>The major <strong>downside</strong> of this library is that it doesn&#8217;t seem to be maintained anymore; the last release is from 2008, and there seem to be various conflicts with recent versions of Django. A real shame!</p>
<h3>Djubby <a style="font-size: 14px;" href="http://code.google.com/p/djubby/">http://code.google.com/p/djubby/</a></h3>
<p>Djubby (<a href="http://code.google.com/p/djubby/downloads/list">download</a> | <a href="http://code.google.com/p/djubby/wiki/GettingStarted">docs</a>) is a Linked Data frontend for SPARQL endpoints for the <a href="http://www.djangoproject.com/">Django</a> Web framework, adding a Linked Data interface to any existing SPARQL-capable triple stores. </p>
<p>Djubby is quite inspired by Richard Cyganiak&#8217;s <a href="http://www4.wiwiss.fu-berlin.de/pubby/">Pubby</a> (written in Java): it provides a Linked Data interface to local or remote SPARQL protocol servers, it provides dereferenceable URIs by rewriting URIs found in the SPARQL-exposed dataset into the djubby server&#8217;s namespace, and it provides a simple HTML interface showing the data available about each resource, taking care of handling 303 redirects and content negotiation. </p>
<h3>Redland <a style="font-size: 14px;" href="http://librdf.org/">http://librdf.org/</a></h3>
<p>Redland (<a href="http://download.librdf.org/">download</a> | <a href="http://librdf.org/docs/">docs</a> | <a href="http://lists.usefulinc.com/pipermail/redland-dev/">discussiongroup</a>) is an RDF library written in C and including several high-level language APIs providing RDF manipulation and storage. Redland makes available also a Python interface (<a href="http://librdf.org/docs/python.html">intro</a> | <a href="http://librdf.org/docs/pydoc/RDF.html">apidocs</a>) that can be used to manipulate RDF triples. </p>
<p>This library seems to be quite complete and is actively maintained; only potential downside is the installation process. In order to use the python bindings you need to install the C library too (which in turns depends on other C libraries), so (depending on your programming experience and operating system used) just getting up and running might become a challenge.</p>
<h3>SuRF <a style="font-size: 14px;" href="http://packages.python.org/SuRF/">http://packages.python.org/SuRF/</a></h3>
<p>SuRF (<a href="http://packages.python.org/SuRF/install.html#installing-rdflib">install</a> | <a href="http://packages.python.org/SuRF/#documentation">docs</a>) is an Object &#8211; RDF Mapper based on the RDFLIB python library. It exposes the RDF triple sets as sets of resources and seamlessly integrates them into the Object Oriented paradigm of python in a similar manner as ActiveRDF does for ruby.</p>
<h3>Other smaller (but possibly useful) python libraries for rdf:</h3>
<li><a href="http://ivan-herman.name/2007/07/06/sparql-endpoint-interface-to-python/">Sparql Interface to python</a>: a minimalistic solution for querying sparql endpoints using python (<a href="http://www.ivan-herman.net/Misc/PythonStuff/SPARQL/">download</a> | <a href="http://www.ivan-herman.net/Misc/PythonStuff/SPARQL/Doc-SPARQL/">apidocs</a>). <em>UPDATE: Ivan Herman pointed out that this library has been discontinued and merged with the &#8216;SPARQL Endpoint interface to Python&#8217; below.</em></li>
<li><a href="http://sparql-wrapper.sourceforge.net/">SPARQL Endpoint interface to Python</a> another little utility for talking to a SPARQL endpoint, including having select-results mapped to rdflib terms or returned in JSON format (<a href="http://sourceforge.net/projects/sparql-wrapper/">download</a>)</li>
<li><a href="http://code.google.com/p/pysparql/source/browse/trunk/src/sparql.py">PySparql</a>: again, a minimal library that does SELECT and ASK queries on an endpoint which implements the HTTP (GET or POST) bindings of the SPARQL Protocol (<a href="http://code.google.com/p/pysparql/source/browse/trunk/src/sparql.py">code page</a>)</li>
<li><a href="https://github.com/mnot/sparta/">Sparta</a>: Sparts is a simple, resource-centric API for RDF graphs, built on top of RDFLIB. </li>
<li><a href="http://oort.to/">Oort</a>: another Python toolkit for accessing RDF graphs as plain objects, based on RDFLIB. The project homepage hasn&#8217;t been updated for a while, although there is trace of recent activity on its <a href="http://code.google.com/p/oort/">google project</a> page.</li>
<p>&nbsp;</p>
<h2>2. RDF Triplestores that are python-friendly</h2>
<p>An important component of a linked-data application is the <a href="http://en.wikipedia.org/wiki/Triplestore">triplestore</a> (that is, an RDF database): many commercial and non-commercial triplestores are available, but only a few offer out-of-the-box python interfaces. Here&#8217;s a list of them:</p>
<h3>Allegro Graph <a style="font-size: 14px;" href="http://www.franz.com/agraph/allegrograph/">http://www.franz.com/agraph/allegrograph/</a></h3>
<p><a href="http://www.franz.com/agraph/allegrograph/">AllegroGraph</a> RDFStore is a high-performance, persistent RDF graph database. AllegroGraph uses disk-based storage, enabling it to scale to billions of triples while maintaining superior performance. Unfortunately, the official version of AllegroGraph is not free, but it is possible to get a <a href="http://www.franz.com/agraph/allegrograph/ag_commercial_edition.lhtml">free version</a> of it (it limits the DB to 50 million triples, so although useful for testing or development it doesn&#8217;t seem a good solution for a production environment).</p>
<p>The Allegro Graph Python API (<a href="http://www.franz.com/agraph/allegrograph/clients.lhtml">download</a> | <a href="http://www.franz.com/agraph/support/documentation/current/python-tutorial/python-tutorial-40.html">docs</a> | <a href="http://www.franz.com/agraph/support/documentation/v4/python-tutorial/python-API-40.html">reference</a>) offers convenient and efficient access to an <a href="http://www.franz.com/agraph/allegrograph/">AllegroGraph</a> server from a Python-based application. This API provides methods for creating, querying and maintaining RDF data, and for managing the stored triples.</p>
<li>A hands-on overview of what&#8217;s like to work with AllegroGraph and python can be found here: <a href="http://www.snee.com/bobdc.blog/2009/04/getting-started-with-allegrogr.html">Getting started with AllegroGraph</a>.</li>
<h3>Open Link Virtuoso <a style="font-size: 14px;" href="http://virtuoso.openlinksw.com/">http://virtuoso.openlinksw.com/</a></h3>
<p><a href="http://en.wikipedia.org/wiki/Virtuoso_Universal_Server">Virtuoso Universal Server</a> is a middleware and database engine hybrid that combines the functionality of a traditional RDBMS, ORDBMS, virtual database, RDF, XML, free-text, web application server and file server functionality in a single system. Rather than have dedicated servers for each of the aforementioned functionality realms, Virtuoso is a &#8220;universal server&#8221;; it enables a single multithreaded server process that implements multiple protocols. The open source edition of Virtuoso Universal Server is also known as <a href="http://virtuoso.openlinksw.com/dataspace/dav/wiki/Main/VOSIntro">OpenLink Virtuoso</a>.</p>
<p><a href="http://packages.python.org/virtuoso/">Virtuoso from Python</a> is intended to be a collection of modules for interacting with OpenLink Virtuoso from python. The goal is to provide drivers for `SQLAlchemy` and `RDFLib`. The package is installable from the <a href="http://pypi.python.org/pypi/virtuoso">Python Package Index</a> and source code for development is available in a mercurial repository on <a href="http://bitbucket.org/ww/virtuoso">BitBucket</a>. </p>
<li>A possibly useful example of using Virtuoso from python: <a href="http://www.openlinksw.com/dataspace/kidehen@openlinksw.com/weblog/kidehen@openlinksw.com%27s%20BLOG%20%5B127%5D/1651">SPARQL Guide for Python Developer</a>.</li>
<h3>Sesame <a style="font-size: 14px;" href="http://www.openrdf.org/">http://www.openrdf.org/</a></h3>
<p><a href="http://en.wikipedia.org/wiki/Sesame_(framework)">Sesame</a> is an open-source framework for querying and analyzing RDF data (<a href="http://www.openrdf.org/download.jsp">download</a> | <a href="http://www.openrdf.org/documentation.jsp">documentation</a>). Sesame supports two query languages: SeRQL and Sparql. Sesame&#8217;s API differs from comparable solutions in that it offers a (stackable) interface through wich functionality can be added, and the storage engine is abstracted from the query interface (many other Triplestores can in fact be used through the Sesame API).</p>
<p>It looks as if the best way to interact with Sesame is by using Java; however there is also a pythonic API called <a href="http://pysesame.projects.semwebcentral.org/">pySesame</a>. This is essentially a python wrapper for Sesame&#8217;s REST HTTP API, so the range of operations supported (Log in, Log out, Request a list of available repositories, Evaluate a SeRQL-select, RQL or RDQL query, Extract/upload/remove RDF from a repository) are somehow limited (for example, there does not seem to be any native SPARQL support).</p>
<li>A nice introduction to using Sesame with Python (without pySesame though) can be found in this article: <a href="http://www.jenitennison.com/blog/node/153">Getting Started with RDF and SPARQL Using Sesame and Python</a>.</li>
<h3>Talis platform <a style="font-size: 14px;" href="http://www.talis.com/platform/">http://www.talis.com/platform/</a></h3>
<p>The Talis Platform (<a href="http://docs.api.talis.com/getting-started/platform-faq#TOC-What-is-the-Talis-Platform-">faq</a> | <a href="http://docs.api.talis.com/">docs</a>)is an environment for building next generation applications and services based on Semantic Web technologies. It is a <strong>hosted</strong> system which provides an efficient, robust storage infrastructure. Both arbitrary documents and RDF-based semantic content are supported, with sophisticated query, indexing and search features. Data uploaded on the Talis platform are organized into stores: a <strong>store</strong> is a grouping of related data and metadata. For convenience each store is assigned one or more owners who are the people who have rights to configure the access controls over that data and metadata. Each store provides a uniform REST interface to the data and metadata it manages.</p>
<p>Stores don&#8217;t come free of charge, but through the <a href="http://www.talis.com/platform/cc/">Talis Connected Commons scheme</a> it is possible have quite large amounts of store space for free. The scheme is intended to support a wide range of different forms of data publishing. For example scientific researchers seeking to share their research data; dissemination of public domain data from a variety of different charitable, public sector or volunteer organizations; open data enthusiasts compiling data sets to be shared with the web community.</p>
<p>Good news for pythonistas too: <a href="http://code.google.com/p/pynappl/">pynappl</a> is a simple client library for the Talis Platform. It relies on <a href="http://code.google.com/p/rdflib/">rdflib 3.0</a> and draws inspiration from other similar client libraries.  Currently it is focussed mainly on managing data loading and manipulation of Talis Platform stores (<a href="http://blogs.talis.com/n2/archives/887">this blog post</a> says more about it). </p>
<li>Before trying out the Talis platform you might find useful this blog post: <a href="http://www.jenitennison.com/blog/node/109">Publishing Linked Data on the Talis Platform</a>.</li>
<h3>4store <a style="font-size: 14px;" href="http://4store.org/">http://4store.org/</a></h3>
<p>4store (<a href="http://4store.org/trac/wiki/Download">download</a> | <a href="http://4store.org/about">features</a> | <a href="http://4store.org/trac/wiki/Documentation">docs</a>) is a database storage and query engine that holds RDF data. It has been used by <a href="http://www.garlik.com/">Garlik</a> as their primary RDF platform for three years, and has proved itself to be robust and secure.<br />
4store&#8217;s main strengths are its performance, scalability and stability. It does not provide many features over and above RDF storage and SPARQL queries, but if your are looking for a scalable, secure, fast and efficient RDF store, then 4store should be on your shortlist.</p>
<p>4store offers a number of <a href="http://4store.org/trac/wiki/ClientLibraries">client libraries</a>, among them there are two for python: first, <a href="http://pypi.python.org/pypi/HTTP4Store/0.2">HTTP4Store</a> is a client for the 4Store httpd service &#8211; allowing for easy handling of sparql results, and adding, appending and deleting graphs. Second, <a href="https://github.com/wwaites/py4s">py4s</a>, although this seems to be a much more experimental library (geared towards multi process queries).<br />
Furthemore, there is also an application for the Django web framework called <a href="https://github.com/66laps/django-4store#readme">django-4store</a> that makes it easier to query and load rdf data into 4store when running Django. The application offers some support for constructing sparql-based Django <a href="https://github.com/66laps/django-4store/blob/master/src/fourstore/views.py">views</a>.</p>
<li>This blog post shows how to install 4store: <a href="http://www.jenitennison.com/blog/node/152">Getting Started with RDF and SPARQL Using 4store and RDF.rb </a>.</li>
<p>&nbsp;</p>
<p>End of the survey.. <em>have I missed out on something</em>? Please let me know if I did &#8211; I&#8217;ll try to keep adding stuff to this list as I move on with my project work!</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2011/02/24/survey-of-pythonic-tools-for-rdf-and-linked-data-programming/feed/</wfw:commentRss>
		<slash:comments>24</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">1110</post-id>	</item>
	</channel>
</rss>
