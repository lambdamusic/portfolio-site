<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>nature &#8211; Parerga und Paralipomena</title>
	<atom:link href="http://www.michelepasin.org/blog/tag/nature/feed/" rel="self" type="application/rss+xml" />
	<link>http://www.michelepasin.org/blog</link>
	<description>At the core of all well-founded belief lies belief that is unfounded - Wittgenstein</description>
	<lastBuildDate>Mon, 10 Apr 2017 14:13:16 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.11</generator>
<site xmlns="com-wordpress:feed-additions:1">13825966</site>	<item>
		<title>Exploring SciGraph data using JSON-LD, Elastic Search and Kibana</title>
		<link>http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/</link>
				<comments>http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/#comments</comments>
				<pubDate>Thu, 06 Apr 2017 14:12:05 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[data exploration]]></category>
		<category><![CDATA[elasticsearch]]></category>
		<category><![CDATA[graph]]></category>
		<category><![CDATA[jsonld]]></category>
		<category><![CDATA[kibana]]></category>
		<category><![CDATA[linkeddata]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[scigraph]]></category>
		<category><![CDATA[visualization]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2844</guid>
				<description><![CDATA[Hello there data lovers! In this post you can find some information on how to download and make some sense of the scholarly dataset recently made available by the Springer Nature SciGraph project, by using the freely available Elasticsearch suite of software. A few weeks ago the SciGraph dataset was released (full disclosure: I&#8217;m part [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Hello there data lovers! In this post you can find some information on how to download and make some sense of the scholarly dataset recently made available by the Springer Nature <a href="http://www.springernature.com/scigraph">SciGraph project</a>, by using the freely available <a href="https://en.wikipedia.org/wiki/Elasticsearch">Elasticsearch</a> suite of software.</p>
<p>A few weeks ago the SciGraph dataset was <a href="http://www.springernature.com/gp/group/media/press-releases/springer-nature-scigraph--supporting-open-science-and-the-wider-understanding-of-research/12129614">released</a> (full disclosure: I&#8217;m part of the team who did that!). This is a high quality dataset containing metadata and abstracts about scientific articles published by <a href="https://en.wikipedia.org/wiki/Springer_Nature">Springer Nature</a>, research grants related to them plus other classifications of this content.</p>
<p><img class="alignnone size-full wp-image-3123" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/scigraph.png?w=1116" alt="scigraph.png" width="558" height="142" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/scigraph.png 1888w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/scigraph-300x76.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/scigraph-768x195.png 768w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/scigraph-1024x260.png 1024w" sizes="(max-width: 558px) 100vw, 558px" /></p>
<p>This release of the dataset includes the last 5 years of content &#8211; that&#8217;s already an impressive <strong>32 gigs of data</strong> you can get your hands on. So in this post I&#8217;m going to show how to do that, in particular by transforming the data from the <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF graph</a> format they come with, into a <a href="https://en.wikipedia.org/wiki/JSON">JSON format</a> which is more suited for application development and analytics.</p>
<p>We will be using two free-to-download products, <a href="http://ontotext.com/products/graphdb/">GraphDB</a> and <a href="https://www.elastic.co/">Elasticsearch</a>, so you&#8217;ll have to install them if you haven&#8217;t got them already. But no worries, that&#8217;s pretty straighforward, as you&#8217;ll see below.</p>
<h2>1. Hello SciGraph Linked Data</h2>
<p>First things first, we want to get hold of the SciGraph RDF datasets of course. That&#8217;s pretty easy, just head over to the SciGraph <a href="https://github.com/springernature/scigraph/wiki#downloads">downloads page</a> and get the following datasets:</p>
<ul>
<li><strong>Ontologies</strong>: the main <a href="http://s3-service-broker-live-afe45d64-24d0-4a96-b6a8-23b79e885eb7.s3-website.eu-central-1.amazonaws.com/2017-02-15/springernature-scigraph-ontologies.2017-02-15.nt.bz2">schema</a> behind SciGraph.</li>
<li><strong>Articles</strong> <strong>&#8211; 2016</strong>: all the core <a href="http://s3-service-broker-live-afe45d64-24d0-4a96-b6a8-23b79e885eb7.s3-website.eu-central-1.amazonaws.com/2017-02-15/springernature-scigraph-2016-articles.2017-02-15.nt.bz2">articles</a> metadata for one year.</li>
<li><strong>Grants</strong>: <a href="http://s3-service-broker-live-afe45d64-24d0-4a96-b6a8-23b79e885eb7.s3-website.eu-central-1.amazonaws.com/2017-02-15/springernature-scigraph-grants.2017-02-15.nt.bz2">grants</a> metadata related to those articles.</li>
<li><strong>Journals</strong>: full list of Springer Nature <a href="http://s3-service-broker-live-afe45d64-24d0-4a96-b6a8-23b79e885eb7.s3-website.eu-central-1.amazonaws.com/2017-02-15/springernature-scigraph-journals.2017-02-15.nt.bz2">journal catalogue</a>.</li>
<li><strong>Subjects</strong>: classification of <a href="http://s3-service-broker-live-afe45d64-24d0-4a96-b6a8-23b79e885eb7.s3-website.eu-central-1.amazonaws.com/2017-02-15/springernature-scigraph-subjects.2017-02-15.nt.bz2">research areas</a> developed by Springer Nature.</li>
</ul>
<p>That&#8217;s pretty much everything, only thing we&#8217;re getting only one year worth of articles as that&#8217;s enough for the purpose of this exercise (~300k articles from 2016).</p>
<p>Next up, we want to get a couple of other datasets SciGraph depends on:</p>
<ul>
<li><strong>GRID</strong>: a catalogue of the world&#8217;s research organisations. Make sure you get both the <a href="http://www.grid.ac/ontology/">ontology</a> and one of the <a href="https://www.grid.ac/downloads">latest releases</a>, within which you can find an RDF implementation too.</li>
<li><strong>Field Of Research codes</strong>: another classification scheme used in SciGraph, developed by the <a href="https://vocabs.ands.org.au/anzsrc-for">Australian and New Zealand Standard Research Classification</a> organization.</li>
</ul>
<p>That&#8217;s it! Time for a cup of coffee.</p>
<h2>2. Python to the help</h2>
<p>We will be doing a bit of data manipulation  in the next sections and Python is a great language for that sort of thing. Here&#8217;s what we need to get going:</p>
<ol>
<li><strong>Python</strong>. Make sure you have <a href="https://wiki.python.org/moin/BeginnersGuide/Download">Python installed</a> and also <a href="https://packaging.python.org/installing/">Pip</a>, the Python package manager (any Python version <strong>above 2.7</strong> should be ok).</li>
<li><strong>GitHub project</strong>. I&#8217;ve created a few scripts for this tutorial, so head over to the <a href="https://github.com/lambdamusic/hello-scigraph">hello-scigraph project on GitHub</a> and download it to your computer. Note: the project contains all the Python scripts needed to complete this tutorial, but of course you should feel free to modify them or write from scratch if you fancy it!</li>
<li><strong>Libraries</strong>. Install all the dependencies for the hello-scigraph project to run. You can do that by cd-ing into the project folder and running <code style="display: inline; padding: 0px;">pip install -r requirements.txt</code> (ideally within a <a href="http://python-guide-pt-br.readthedocs.io/en/latest/dev/virtualenvs/">virtual environment</a>, but that&#8217;s up to you).</li>
</ol>
<h2>3. Loading the data into GraphDB</h2>
<p>So, you should have by now 8 different files containing data (after step 1 above). Make sure they&#8217;re all in the same folder and that all of them have been unzipped (if needed), then head over to the <a href="http://ontotext.com/graphdb-8-enterprise-linked-data/">GraphDB website</a> and download the free version of the triplestore (you may have to sign up first).</p>
<p>The <a href="http://graphdb.ontotext.com/documentation/free/quick-start-guide.html#run-graphdb-as-a-stand-alone-server">online documentation</a> for GraphDB is pretty good, so it should be easy to get it up and running. In essence, you have to do the following steps:</p>
<ol>
<li><strong>Launch the application</strong>: for me, on a mac, I just had to double click the GraphDB icon &#8211; nice!</li>
<li><strong>Create a</strong> <a href="http://graphdb.ontotext.com/documentation/free/quick-start-guide.html#create-a-repository">new repository</a>: this is the equivalent of a database within the triplestore. Call this repo <span class="pl-pds">&#8220;</span><strong>scigraph-2016</strong><span class="pl-pds">&#8221; so that we&#8217;re all synced for the following steps.</span></li>
</ol>
<p>Next thing, we want a script to load our RDF files into this empty repository. So cd into the directory containg the GitHub project (from step 2) and run the following command:</p>
<pre style="background: lightgray; padding: 5px;">python -m hello-scigraph.loadGraphDB ~/scigraph-downloads/</pre>
<p>The &#8220;loadGraphDB&#8221; script goes through all RDF files in the &#8220;scigraph-downloads&#8221; directory and loads them into the <strong>scigraph-2016 </strong>repository (note: you must replace &#8220;scigraph-downloads&#8221; with the actual path to the folder you downloaded content in step 1 above).</p>
<p><strong>So, to recap:</strong> this script is now loading more than 35 million triples into your local graph database. Don&#8217;t be surprised if it&#8217;ll take some time (in particular the &#8216;articles-2016&#8217; dataset, by far the biggest) so it&#8217;s time to take a break or do something else.</p>
<p>Once the process it&#8217;s finished, you should be able to <a href="http://graphdb.ontotext.com/documentation/free/quick-start-guide.html#explore-your-data-and-class-relationships">explore your data via the GraphDB workbench</a>.  It&#8217;ll look something like this:</p>
<p><img class="aligncenter size-large wp-image-2954" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/GraphDB-class-hierarchy-1024x525.png" alt="GraphDB-class-hierarchy" width="1024" height="525" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/GraphDB-class-hierarchy-1024x525.png 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/GraphDB-class-hierarchy-300x154.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/GraphDB-class-hierarchy-768x394.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></p>
<h2>4. Creating an Elasticsearch index</h2>
<p>We&#8217;re almost there. Let&#8217;s head over to the <a href="https://www.elastic.co/downloads/elasticsearch">Elasticsearch website</a> and <strong>download</strong> it. Elasticsearch is a powerful, distributed, JSON-based search and analytics engine so we&#8217;ll be using it to build an analytics dashboard for the SciGraph data.</p>
<p>Make sure Elastic is running (run <code style="display: inline; padding: 0px;">bin/elasticsearch</code> (or <code style="display: inline; padding: 0px;">bin\elasticsearch.bat</code> on Windows), then cd into the hello-scigraph Python project (from step 2) in order to run the following script:</p>
<pre style="background: lightgray; padding: 5px;">python -m hello-scigraph.loadElastic</pre>
<p>If you <a href="https://github.com/lambdamusic/hello-scigraph/blob/master/hello-scigraph/loadElastic.py">take a look at the source code</a>, you&#8217;ll see that the script does the following:</p>
<ol>
<li><strong>Articles loading:</strong> extracts articles references from GraphDB in batches of 200.</li>
<li><strong>Articles metadata extraction:</strong> for each article, we <a href="https://github.com/lambdamusic/hello-scigraph/blob/master/hello-scigraph/queries.py">pull out all relevant metadata</a> (e.g. title, DOI, authors) plus related information (e.g. author GRID organizations, geo locations, funding info etc..).</li>
<li><strong>Articles metadata simplification: </strong> some intermediate nodes coming from the orginal RDF graph are dropped and replaced with a flatter structure which uses a a temporary dummy schema (<code style="display: inline; padding: 0px;">prefix es: &lt;http://elastic-index.scigraph.com/&gt;</code> It doesn&#8217;t matter what we call that schema, but what&#8217;s important is to that we want to simplify the data we put into the Elastic search index. That&#8217;s because while the Graph layer is supposed to facilitate <em>data integration </em>and hence it benefits from a rich semantic representation of information, the <em>search layer</em> is more geared towards performance and retrieval hence a leaner information structure can dramatically speed things up there.</li>
<li><strong>JSON-LD transformation</strong>: the simplified RDF data structure is <a href="http://json-ld.org/">serialized as JSON-LD</a> &#8211; one of the many serializations available for RDF. JSON-LD is of course valid JSON, meaning that we can put that into Elastic right away. This is a bit of a shortcut actually, in fact for a more fine-grained control of how the JSON looks like,  it&#8217;s probably better to transform the data into JSON using some ad-hoc mechanism. But for the purpose of this tutorial it&#8217;s more than enough.</li>
<li><strong>Elastic index creation.</strong> Finally, we can load the data into an Elastic index called &#8211; guess what &#8211; &#8220;hello-scigraph&#8221;.</li>
</ol>
<p>Two more things to point out:</p>
<ul>
<li><strong>Long queries.</strong> The Python script enforces a 60 seconds <a href="https://github.com/lambdamusic/hello-scigraph/blob/master/hello-scigraph/timeout.py">time-out </a>on the GraphDB queries, so in case things go wrong with some articles data the script should keep running.</li>
<li><strong>Memory issues.</strong> The script stops for 10 seconds after each batch of 200 articles (<code style="display: inline; padding: 0px;">time.sleep(10)</code>). Had to do this to prevent GraphDB on my laptop from running out of memory. Time to catch some breath!</li>
</ul>
<p>That&#8217;s it! <strong>Time for another break  now.</strong> A pretty long one actually &#8211; loading all the data took around 10 hours on my (rather averaged spec&#8217;ed) laptop so you may want to do that overnight or get hold of a faster machine/server.</p>
<p>Eventually, once the loading script is finished, you can issue this command from the command line to see how much data you&#8217;ve loaded into the Elastic index  &#8220;hello-scigraph&#8221;. Bravo!</p>
<pre style="background: lightgray; padding: 5px;">curl -XGET 'localhost:9200/_cat/indices/'</pre>
<h2>5. Analyzing the data with Kibana</h2>
<p>Loading the data in Elastic already opens up a number of possibilites &#8211; check out the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html">search APIs </a>for some ideas &#8211; however there&#8217;s an even quicker way to analyze the data: <strong>Kibana</strong>. <a href="https://www.elastic.co/products/kibana">Kibana</a> is another free product in the Elastic Search suite, which provides an extensible user interface for configuring and managing all aspects of the Elastic Stack.</p>
<p>So let&#8217;s get started with Kibana: <a href="https://www.elastic.co/downloads/kibana">download it</a> and set it up using the online instructions, then point your browser at <a href="http://localhost:5601">http://localhost:5601 </a>.</p>
<p>You&#8217;ll get to the Kibana dashboard which shows the index we just created. Here you can perform any kind of searches and see the raw data as JSON.</p>
<p>What&#8217;s even more interesting is the <strong>visualization tab</strong>. Results of searches can be rendered as line chart, pie charts etc.. and more dimensions can be added via &#8216;buckets&#8217;. See below for some quick examples, but really, the possibilities are endless!</p>

<a href='http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/kibana-super-collider-1/'><img width="300" height="153" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-1-300x153.png" class="attachment-medium size-medium" alt="" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-1-300x153.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-1-768x391.png 768w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-1-1024x521.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>
<a href='http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/kibana-super-collider-2/'><img width="300" height="153" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-2-300x153.png" class="attachment-medium size-medium" alt="" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-2-300x153.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-2-768x391.png 768w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-2-1024x521.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>
<a href='http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/kibana-super-collider-3/'><img width="300" height="171" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-3-300x171.png" class="attachment-medium size-medium" alt="" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-3-300x171.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-3-768x438.png 768w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-3-1024x584.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>
<a href='http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/kibana-super-collider-4/'><img width="300" height="173" src="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-4-300x173.png" class="attachment-medium size-medium" alt="" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-4-300x173.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-4-768x444.png 768w, http://www.michelepasin.org/blog/wp-content/uploads/2017/04/Kibana-super-collider-4-1024x592.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /></a>

<h2>Conclusion</h2>
<p>This post should have given you enough to realise that:</p>
<ol>
<li>The <strong>SciGraph dataset</strong> contain an impressive amount of high-quality scholarly publications metadata which can be used for things like literature search, research statistics etc..</li>
<li>Even though you&#8217;re not familiar with Linked Data and the RDF family of languages, it&#8217;s not hard to get going with a triplestore and then <strong>transform the data</strong> into a more widely used format like JSON.</li>
<li>Finally, <strong>Elasticsearch</strong> and especially <strong>Kibana</strong> are fantastic tools for data analysis and exploration! Needless to say, in this post I&#8217;ve just scratched the surface of what could be done with it.</li>
</ol>
<p>Hope this was fun, any questions or comments, you know the drill :-)</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2017/04/06/exploring-scigraph-data-using-elastic-search-and-kibana/feed/</wfw:commentRss>
		<slash:comments>4</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">2844</post-id>	</item>
		<item>
		<title>Nature.com Subjects Stream Graph</title>
		<link>http://www.michelepasin.org/blog/2016/01/03/nature-com-subjects-stream-graph/</link>
				<pubDate>Sun, 03 Jan 2016 00:28:08 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[d3]]></category>
		<category><![CDATA[infographics]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[visualization]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2750</guid>
				<description><![CDATA[The nature.com subjects stream graph displays the distribution of content across the subject areas covered by the nature.com portal. This is an experimental interactive visualisation based on a freely available dataset from the nature.com linked data platform, which I&#8217;ve been working on in the last few months. The main visualization provides an overview of selected [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>The <a href="http://www.nature.com/developers/hacks/articles/stream/by-subject/">nature.com subjects stream graph</a> displays the distribution of content across the subject areas covered by the nature.com portal. </p>
<p>This is an experimental interactive visualisation based on a freely available dataset from the <a href="http://www.nature.com/ontologies/datasets/">nature.com linked data platform</a>, which I&#8217;ve been working on in the last few months.</p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph6.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph6-1024x657.png" alt="streamgraph" width="600" class="alignnone size-large wp-image-2761" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph6-1024x657.png 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph6-300x192.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph6-900x577.png 900w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>The main visualization provides an overview of selected content within the level 2 disciplines of the <a href="http://www.nature.com/ontologies/models/subjects/">NPG Subjects Ontology</a>. By clicking on these, it is then possible to explore more specific subdisciplines and their related articles.</p>
<p><span style='text-decoration:underline;'>For those of you who are not familiar with the Subjects Ontology</span>: this is a categorization of scholarly subject areas which are used for the indexing of content on nature.com. It includes subject terms of varying levels of specificity such as Biological sciences (top level), Cancer (level 2), or B-2 cells (level 7). In total there are more than 2500 subject terms, organized into a <a href="http://www.nature.com/developers/hacks/subjects/tree">polyhierarchical tree</a>.</p>
<p>Starting in 2010, the various journals published on nature.com have adopted the subject ontology to tag their articles (note: different journals have started doing this at different times, hence some variations in the graph starting dates).</p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph22.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph22.png" alt="streamgraph2" width="600"  class="alignnone size-full wp-image-2764" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph22.png 864w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph22-300x271.png 300w" sizes="(max-width: 864px) 100vw, 864px" /></a></p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33-1024x472.png" alt="streamgraph3" width="600"  class="alignnone size-large wp-image-2763" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33-1024x472.png 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33-300x138.png 300w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33-900x415.png 900w, http://www.michelepasin.org/blog/wp-content/uploads/2014/10/streamgraph33.png 1591w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>The visualization makes use of various <a href="http://d3js.org/">d3.js</a> modules, plus some simple customizations here and there. The hardest part of the work was putting the different page components together, to the effect of a more fluent &#8216;narrative&#8217; achieved by gradually zooming into the data. </p>
<p>The back end is a <a href="https://www.djangoproject.com/">Django</a> web application with a relational database. The original dataset is <a href="http://www.nature.com/ontologies/downloads/">published as RDF</a>, so in order to use the Django APIs I&#8217;ve recreated it as a relational model. That let me also add a few extra data fields containing search indexes (e.g. article counts per month), so to make the stream graph load faster. </p>
<p>Comments or suggestions, as always very welcome. </p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">2750</post-id>	</item>
		<item>
		<title>Is wikipedia a valid source of scientific knowledge?</title>
		<link>http://www.michelepasin.org/blog/2015/09/02/is-wikipedia-a-valid-source-of-scientific-knowledge/</link>
				<comments>http://www.michelepasin.org/blog/2015/09/02/is-wikipedia-a-valid-source-of-scientific-knowledge/#comments</comments>
				<pubDate>Wed, 02 Sep 2015 13:15:25 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[citation]]></category>
		<category><![CDATA[d3]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[wikipedia]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2689</guid>
				<description><![CDATA[Is wikipedia a valid source of scientific knowledge? Many would say yes. Others are still quite skeptical, or maybe just cautious about it. What seems to be the case though &#8211; and this is what this post is about &#8211; is that wikipedians are increasingly including references to scientific literature, and when they do it [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Is wikipedia a valid source of scientific knowledge? Many would say <a href="http://www.nature.com/news/2008/081216/full/news.2008.1312.html">yes</a>. Others are still quite skeptical, or maybe just <a href="http://www.quora.com/How-reliable-is-Wikipedia-as-a-source-of-information-and-why">cautious</a> about it. What seems to be the case though &#8211; and this is what this post is about &#8211; is that wikipedians are increasingly including references to scientific literature, and when they do it they do it right. </p>
<p>Based on data we&#8217;ve recently <a href="http://www.nature.com/ontologies/linksets/articles/">extracted</a> from Wikipedia, it looks like that the vast majority of <strong>citations to nature.com</strong> content have been done according to the established scientific practice (i.e. using <a href="https://en.wikipedia.org/wiki/Digital_object_identifier">DOIs</a>). Which makes you think that whoever added those citations is either a scientist or has some familiarity with science. </p>
<p>In the context of the <a href="http://www.nature.com/ontologies/">nature.com ontologies portal</a> we&#8217;ve done some work aimed at surfacing links between our articles and other datasets. Wikipedia and <a href="http://wiki.dbpedia.org/">DBpedia</a> (an RDF database version of wikipedia) have come to our attention quite soon: <em>how much do wikipedia articles cite scientific content published on nature.com</em>? Also, <em>how well</em> do they cite it? </p>
<p>So here&#8217;s an <a href="http://www.nature.com/developers/hacks/wikilinks/">interactive visualization</a> that lets you see all incoming references from Wikipedia to the nature.com archive. The actual dataset is encoded in RDF and can be downloaded <a href="http://data.nature.com/downloads/latest/linksets/nq/">here</a> (look for the <em>npg-articles-dbpedia-linkset.2015-08-24.nq.tar.gz</em> file).</p>
<p><a href="http://www.nature.com/developers/hacks/wikilinks/" target="_blank"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2015/09/NewImage.png" alt="NewImage" title="NewImage.png" border="0" width="599" height="338" style="" /></a></p>
<p>&nbsp;</p>
<h2>About the data</h2>
<p>In a nutshell, what we&#8217;ve done was simply extracting all mentions of either NPG DOIs or nature.com links using the wikipedia APIs (for example, see <a href="https://en.wikipedia.org/w/index.php?title=Special%3ASearch&#038;profile=default&#038;search=%2210.1038%2Fng1285%22&#038;fulltext=Search">all references to the DOI &#8220;10.1038/ng1285&#8221;</a>). </p>
<p>These links have then been validated against the nature.com articles database and encoded in RDF in two ways: a <a href="http://www.essepuntato.it/lode/http://purl.org/spar/cito">cito:isCitedBy</a> relationship links the article URI to the citing Wikipedia page, and a <a href="http://xmlns.com/foaf/spec/">foaf:topic</a> relationship links the same article URI to the corresponding DBpedia page.</p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2015/09/Screen-Shot-2015-09-03-at-12.37.33-PM.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2015/09/Screen-Shot-2015-09-03-at-12.37.33-PM.png" alt="Screen Shot 2015 09 03 at 12 37 33 PM" title="Screen Shot 2015-09-03 at 12.37.33 PM.png" border="0" width="600" /></a></p>
<p>In total there are <strong>51309 links over 145 years</strong>. </p>
<p>Quite interestingly, the vast majority of these links are explicit DOI references (only ~900 were links to nature.com without a DOI). So, it seems that people do recognize the importance of DOIs even within a loosely controlled context like wikipedia.</p>
<h2>Using the dataset</h2>
<p>Considering that for many wikipedia is become the <em>de facto</em> largest and most cited encyclopedia out there (see the articles below), this may be an interesting dataset to <strong>analyze</strong> e.g. to highlight citation patters of influential articles.</p>
<p>Also, this could become quite useful as a data source for <strong>content enrichment</strong>: the wikipedia links could be used to drive subject tagging, or they could even be presented to readers on article pages e.g. as contextual information.</p>
<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2015/09/toparticles.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2015/09/toparticles.png" alt="Toparticles" title="toparticles.png" border="0" width="700"  /></a></p>
<p>We haven&#8217;t really had time to explore any follow up on this work, but hopefully we&#8217;ll do that soon.  </p>
<p>All of this data is open source and freely available on <a href="http://www.nature.com/ontologies/">nature.com/ontologies</a>. So if you&#8217;re reading this and have more ideas about potential uses or just want to collaborate, please do <a href="http://www.michelepasin.org/contact/">get in touch</a>!</p>
<h2>Caveats</h2>
<p>This dataset is obviously just a <strong>snaphot</strong> of wikipedia links at a specific moment in time. </p>
<p>If one were to use these data within a real-world application he&#8217;d probably want to come up with some strategy to keep it up to date (e.g. monitoring the <a href="https://meta.wikimedia.org/wiki/IRC/Channels#Recent_changes">Wikipedia IRC recent changes channel</a>).</p>
<p>Good news is, work is already happening in this space:</p>
<li><strong>CrossRef</strong> is looking at collecting citation events from Wikipedia in real time and release these data freely as part of their service e.g. see <a href="http://crosstech.crossref.org/2015/05/coming-to-you-live-from-wikipedia.html">http://crosstech.crossref.org/2015/05/coming-to-you-live-from-wikipedia.html</a></li>
<li><strong>Altmetric</strong> scans wikipedia for references too e.g. see <a href="http://nature.altmetric.com/details/961190/wikipedia">http://nature.altmetric.com/details/961190/wikipedia</a> and <a href="http://www.altmetric.com/blog/new-source-alert-wikipedia/">http://www.altmetric.com/blog/new-source-alert-wikipedia/</a>, however the source data is not freely available.</li>
<p>&nbsp;</p>
<h2>Readings</h2>
<p>Finally, here are a couple of interesting background readings I&#8217;ve found in the nature.com archive:</p>
<li><em>Wikipedia rival calls in the experts</em> (2006) <a href="http://www.nature.com/nature/journal/v443/n7111/full/443493a.html">http://www.nature.com/nature/journal/v443/n7111/full/443493a.html</a></li>
<li><em>Publish in Wikipedia or perish</em> (2008) <a href="http://www.nature.com/news/2008/081216/full/news.2008.1312.html">http://www.nature.com/news/2008/081216/full/news.2008.1312.html</a></li>
<li><em>Time to underpin Wikipedia wisdom</em> (2010) <a href="http://www.nature.com/nature/journal/v468/n7325/full/468765c.html">http://www.nature.com/nature/journal/v468/n7325/full/468765c.html</a></li>
<p><em>Enjoy</em>!</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2015/09/02/is-wikipedia-a-valid-source-of-scientific-knowledge/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">2689</post-id>	</item>
		<item>
		<title>A sneak peek at Nature.com articles&#8217; archive</title>
		<link>http://www.michelepasin.org/blog/2015/06/08/a-sneak-peek-at-nature-com-articles-archive/</link>
				<comments>http://www.michelepasin.org/blog/2015/06/08/a-sneak-peek-at-nature-com-articles-archive/#comments</comments>
				<pubDate>Mon, 08 Jun 2015 21:26:58 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Just Blogging]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[d3]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[publishing]]></category>
		<category><![CDATA[visualization]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2632</guid>
				<description><![CDATA[We&#8217;re getting closer to releasing the full set of metadata covering over one million articles published by Nature Publishing Group since 1845. So here&#8217;s a sneak peek at this dataset, in the form of a simple d3.js visual summary of what soon will be available to download and reuse. In the last months I&#8217;ve been [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>We&#8217;re getting closer to releasing the full set of metadata covering over one million articles published by Nature Publishing Group since 1845. So here&#8217;s a sneak peek at this dataset, in the form of a simple d3.js visual summary of what soon will be available to download and reuse.  </p>
<p>In the last months I&#8217;ve been working with my colleagues at Macmillan Science and Education on an <a href="http://www.nature.com/ontologies/">open data portal</a> that makes available to the public many of the taxonomies and ontologies we use internally for organising the content we publish.  </p>
<p>This is part of our ongoing involvement with linked data and semantic technologies, aimed both at leveraging these tools to the end of transforming the publishing workflow into a <a href="http://www.quora.com/What-is-dynamic-semantic-publishing">more dynamic platform</a>, and at contributing to the evolving <a href="http://linkeddata.org/">web of open data</a> with a rich dataset of scientific articles metadata.</p>
<p>The articles dataset includes metadata about all articles published by the <a href="http://en.wikipedia.org/wiki/Nature_%28journal%29">Nature</a> journal, of course. But not only: the <a href="http://www.scientificamerican.com/">Scientific American</a>, <a href="http://www.nature.com/nm/index.html">Nature Medicine</a>, <a href="http://www.nature.com/ng/index.html">Nature Genetics</a> and many other titles are also part of it (note: the full list can be downloaded as raw data <a href="http://www.nature.com/ontologies/models/journals/">here</a>). </p>
<p><a href="http://bl.ocks.org/lambdamusic/raw/bfcaa40fa350778883fe/"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-22.24.15.png"  alt="Screen Shot 2015 06 08 at 22 24 15" border="0" width="600" style="width: 600px; margin-left:auto; margin-right:auto; " /></a></p>
<p>The first diagram shows how many articles have been published each year since <a href="http://www.nature.com/search?year_range=1845">1845</a> (the start year of Scientific American). Nature began only a few years later in <a href="http://www.nature.com/search?year_range=1869">1869</a>; the curve getting steeper in the 90s instead corresponds to the exponential increase in publications due to the progressive specialisation of scientific journals (e.g. all the nature-branded titles). </p>
<p>The second diagram instead shows the increase in publication volumes on an incremental scale. We&#8217;ve now reached the <strong>1M articles and counting</strong>! </p>
<p><a href="http://bl.ocks.org/lambdamusic/raw/bfcaa40fa350778883fe/"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2015/06/Screen-Shot-2015-06-08-at-22.25.09.png"  alt="Screen Shot 2015 06 08 at 22 25 09" border="0" width="600" style="width: 600px; margin-left:auto; margin-right:auto; " /></a></p>
<p>In order to create the charts I played around with a nifty example from Mike Bostock (<a href="http://bl.ocks.org/mbostock/3902569">http://bl.ocks.org/mbostock/3902569</a>) and added a couple of extra things to it. </p>
<p>The full source code is on <a href="http://bl.ocks.org/lambdamusic/bfcaa40fa350778883fe">Github</a>. </p>
<p>Finally, worth mentioning that this metadata had already been made available a <a href="http://www.nature.com/press_releases/ldp.html">few of years ago</a> under the CC0 license: you can still access it <a href="http://www.nature.com/ontologies/releases/archive/">here</a>. <strong>This upcoming release</strong> though makes it available in the context of a much more <strong>precise and stable</strong> set of ontologies. Meaning that the semantics of the dataset is more clearly laid out and <strong>consistent</strong>. </p>
<p>So stay tuned for more! ..and if you plan/would like to reuse these datasets please do get in touch, either here of by emailing <a href=mailto:developers@nature.com>developers@nature.com</a>. </p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2015/06/08/a-sneak-peek-at-nature-com-articles-archive/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">2632</post-id>	</item>
		<item>
		<title>Nature.com subject pages available online!</title>
		<link>http://www.michelepasin.org/blog/2014/06/23/nature-com-subject-pages-available-online/</link>
				<pubDate>Mon, 23 Jun 2014 14:45:00 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Information Architecture]]></category>
		<category><![CDATA[Just Blogging]]></category>
		<category><![CDATA[Semantic Web]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[ontology]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=2454</guid>
				<description><![CDATA[Subject pages are pages that aggregate content from across nature.com based on the tagging of that content by NPG subject ontology terms. After six months of work on this project we&#8217;ve finally launched the first release of the site, which is reachable online at http://www.nature.com/subjects. Hooray! This has been a particularly challenging experience cause I&#8217;ve [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Subject pages are pages that aggregate content from across nature.com based on the tagging of that content by <a href="http://www.michelepasin.org/blog/2013/06/21/messing-around-wih-d3-js-and-hierarchical-data/">NPG subject ontology</a> terms. After six months of work on this project we&#8217;ve finally launched the first release of the site, which is reachable online at <a href="http://www.nature.com/subjects">http://www.nature.com/subjects</a>. Hooray!</p>
<p>This has been a particularly challenging experience cause I&#8217;ve essentially been wearing two hats for the past six months: <em>product owner</em>, leading the team in the day to day activities and prioritization of tasks, and <em>information architect</em>, dealing with the way content is organized and presented to users (my usual role). </p>
<p>In a nutshell, the goal of the <a href="http://www.nature.com/subjects">project</a> was to help our readers discover content more easily by using an internally-developed subject ontology to publish a page per term. The ontology is actually a <a href="http://www.michelepasin.org/blog/2013/06/21/messing-around-wih-d3-js-and-hierarchical-data/">poly-hierarchical taxonomy of scientific topics</a>, which has been used in the last couple of years to tag all articles published on nature.com. </p>
<p>Besides helping users browse the site more easily, <a href="http://www.nature.com/subjects">subject pages</a> also contribute to making NPG content more discoverable via Google and other external search engines. All of this powered by a new backend platform which combines the expressiveness of <strong>linked data technologies</strong> (RDF) with the scalability of more traditional <strong>XML data stores</strong> (MarkLogic). </p>
<p>The main features are:<br />
&#8211; <strong>one page per subject</strong> term which collates all content tagged with that term across nature.com<br />
&#8211; <strong>RSS</strong> and <strong>ATOM</strong> feeds for each of the subject terms (~2500)<br />
&#8211; dedicated pages that collate content from different journals based on their <strong>article types</strong> (e.g. news, research etc..)<br />
&#8211; a <strong>visual tool</strong> to navigate subjects based on the ontology relations<br />
&#8211; subject <strong>email alerts</strong> (to be released in the coming weeks) </p>
<p>It&#8217;s been a lot of work to bring all of this content together within a single application (keep in mind that the content comes from more than <a href="http://www.nature.com/catalog/">80 different journals</a>!) but this is just the beginning. </p>
<p>In the <strong>next months</strong> we&#8217;re looking at extending this work by making this content available in other formats (e.g. RDF), providing more ways to navigate through the data (facets, visualizations) and to integrate it with other datasets available online.. so stay tuned for more!</p>
<p><a href="http://www.nature.com/subjects"><img style="display:block; margin-left:auto; margin-right:auto;" src="http://www.michelepasin.org/blog/wp-content/uploads/2014/06/Screen-Shot-2014-06-23-at-3.35.53-PM.png" alt="Screen Shot 2014 06 23 at 3 35 53 PM" title="Screen Shot 2014-06-23 at 3.35.53 PM.png" border="0" width="700" height="519" /></a></p>
<p>&nbsp;</p>
<p><a href="http://www.nature.com/subjects/computer-modelling"><img style="display:block; margin-left:auto; margin-right:auto;" src="http://www.michelepasin.org/blog/wp-content/uploads/2014/06/Screen-Shot-2014-06-23-at-3.36.24-PM.png" alt="Screen Shot 2014 06 23 at 3 36 24 PM" title="Screen Shot 2014-06-23 at 3.36.24 PM.png" border="0" width="700" height="544" /></a></p>
<p>&nbsp;</p>
<p><a href="http://www.nature.com/subjects/systems-biology"><img style="display:block; margin-left:auto; margin-right:auto;" src="http://www.michelepasin.org/blog/wp-content/uploads/2014/06/Screen-Shot-2014-06-23-at-3.36.48-PM.png" alt="Screen Shot 2014 06 23 at 3 36 48 PM" title="Screen Shot 2014-06-23 at 3.36.48 PM.png" border="0" width="700" height="531" /></a></p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">2454</post-id>	</item>
		<item>
		<title>Listen to the RainForest at Kew Gardens</title>
		<link>http://www.michelepasin.org/blog/2010/08/09/listen-to-the-rainforest-at-kew-gardens/</link>
				<pubDate>Mon, 09 Aug 2010 17:25:17 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Just Blogging]]></category>
		<category><![CDATA[gardens]]></category>
		<category><![CDATA[installation]]></category>
		<category><![CDATA[london]]></category>
		<category><![CDATA[nature]]></category>
		<category><![CDATA[sound]]></category>
		<category><![CDATA[tropical]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=814</guid>
				<description><![CDATA[If you happen to be going to London&#8217;s Kew Gardens, make sure you don&#8217;t miss this nice sound installation by Chris Watson. The installation is on till September 5th and it&#8217;s called Whispering in the Leaves: Whispering in the Leaves features two sound pieces – Dawn and Dusk – composed by Chris from memory using [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="http://www.michelepasin.org/blog/wp-content/uploads/2010/08/Screen-shot-2010-08-09-at-18.17.35.png"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2010/08/Screen-shot-2010-08-09-at-18.17.35.png" alt="Screen shot 2010-08-09 at 18.17.35.png" border="0" width="200" height="200" /></a></p>
<p>If you happen to be going to London&#8217;s <a href="http://www.kew.org/visit-kew-gardens/index.htm">Kew Gardens</a>, make sure you don&#8217;t miss this nice sound installation by <a href="http://www.chriswatson.net/">Chris Watson</a>. The installation is on till September 5th and it&#8217;s called <a href="http://www.whisperingintheleaves.org/">Whispering in the Leaves</a>:</p>
<blockquote><p>Whispering in the Leaves features two sound pieces – <strong>Dawn</strong> and <strong>Dusk</strong> – composed by Chris from memory using his extensive archive of on-location recordings in Central and South American <strong>rainforests</strong>.</p>
<p>Designed specifically for the Palm House, Whispering in the Leaves is the audio equivalent of 3D cinema. Visitors will be immersed in a <strong>dynamic, spatial soundscape of primate calls and birdsong</strong>, backed with a shimmering wall of insect sounds. Some of the species heard are currently unknown to humans. Visitors will experience the heard but never seen.</p>
<p>Diffused through <strong>80 speakers</strong>, the two compositions will be transmitted at <strong>hourly</strong> <strong>intervals</strong> throughout the day &#8211; Dawn in the morning and Dusk in the afternoon. Each lasts for <strong>15-20 minute durations</strong> – the approximate time it takes for the transitions between darkness and daylight in the dense tropical vegetation.</p></blockquote>
<p>The website makes available some of the nature recordings too.</p>
<p><object width="400" height="225"><param name="allowfullscreen" value="true" /><param name="allowscriptaccess" value="always" /><param name="movie" value="http://vimeo.com/moogaloop.swf?clip_id=11337042&amp;server=vimeo.com&amp;show_title=1&amp;show_byline=0&amp;show_portrait=1&amp;color=00ADEF&amp;fullscreen=1&amp;autoplay=0&amp;loop=0" /></object></p>
<p>&#8230;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">814</post-id>	</item>
	</channel>
</rss>
