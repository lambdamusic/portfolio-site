<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>algorithmiccomposition &#8211; Parerga und Paralipomena</title>
	<atom:link href="http://www.michelepasin.org/blog/tag/algorithmiccomposition/feed/" rel="self" type="application/rss+xml" />
	<link>http://www.michelepasin.org/blog</link>
	<description>At the core of all well-founded belief lies belief that is unfounded - Wittgenstein</description>
	<lastBuildDate>Wed, 10 Feb 2021 18:13:18 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.11</generator>
<site xmlns="com-wordpress:feed-additions:1">13825966</site>	<item>
		<title>Extempore functions explorer updated to latest release (v0.8.7)</title>
		<link>http://www.michelepasin.org/blog/2021/02/01/extempore-functions-explorer-updated-to-latest-release-v0-8-7/</link>
				<pubDate>Mon, 01 Feb 2021 13:07:55 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[extempore]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3435</guid>
				<description><![CDATA[The Extempore functions explorer has been updated with the latest version of the Extempore programming language: v0.8.7 Try it out at: http://hacks2019.michelepasin.org/extempore/ The Extempore functions explorer is a little webapp I built a while ago in order to make it easier to browse (and learn about) the Extempore music-programming language. For more background, see also [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>The Extempore functions explorer has been updated with the latest version of the Extempore programming language: <a href="https://github.com/digego/extempore/tree/v0.8.7">v0.8.7</a></p>
<p>Try it out at: <a href="http://hacks2019.michelepasin.org/extempore/" target="_blank" rel="noopener noreferrer">http://hacks2019.michelepasin.org/extempore/</a></p>
<p>The Extempore functions explorer is a little webapp I built a while ago in order to make it easier to browse (and learn about) the Extempore music-programming language.</p>
<p>For more background, see also the <a href="http://www.michelepasin.org/projects/impromptudocs/">project homepage</a>.</p>
<p><img class="  wp-image-3436 aligncenter" src="http://www.michelepasin.org/blog/wp-content/uploads/2021/02/xtm-explorer.gif" alt="xtm-explorer.gif" width="545" height="467" /></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3435</post-id>	</item>
		<item>
		<title>A new livecoding project: &#8216;The Musical Code&#8217;</title>
		<link>http://www.michelepasin.org/blog/2020/11/23/a-new-livecoding-project-the-musical-code/</link>
				<pubDate>Mon, 23 Nov 2020 05:58:29 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[extempore]]></category>
		<category><![CDATA[github]]></category>
		<category><![CDATA[impromptu]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=3446</guid>
				<description><![CDATA[I&#8217;ve started a new livecoding project on Github called The Musical Code, where I&#8217;ll be adding experimental musical code/algorithms created the amazing Extempore programming language (as well as it precursor Impromptu). I have accumulated so much musical-code ideas so I&#8217;ve finally resolved to clean it up, reorganise it and publish it somewhere. Github seemed the best option, these [&#8230;]]]></description>
								<content:encoded><![CDATA[
<p>I&#8217;ve started a new livecoding project on Github called <a href="https://github.com/lambdamusic/The-Musical-Code">The Musical Code</a>, where I&#8217;ll be adding experimental musical code/algorithms created the amazing <a href="https://extemporelang.github.io/">Extempore</a> programming language (as well as it precursor <a href="http://impromptu.moso.com.au/">Impromptu</a>).</p>



<p>I have accumulated so much musical-code ideas so I&#8217;ve finally resolved to clean it up, reorganise it and publish it somewhere. Github seemed the best option, these days:</p>



<div class="wp-block-image"><figure class="aligncenter"><a href="https://github.com/lambdamusic/The-Musical-Code" target="_blank" rel="noreferrer noopener"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2021/02/TheMusicalCodeGithub-1024x757.jpg" alt="" class="wp-image-3447" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2021/02/TheMusicalCodeGithub-1024x757.jpg 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/TheMusicalCodeGithub-300x222.jpg 300w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/TheMusicalCodeGithub-768x568.jpg 768w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/TheMusicalCodeGithub.jpg 1239w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure></div>



<p>Turns out that just the code by itself won&#8217;t do it. Especially considering that the environments I use to &#8216;run it&#8217; (and to make sounds) can rapidly disappear (become obsolete, or get out of fashion!). </p>



<p>Hence there&#8217;s a<a href="https://www.youtube.com/channel/UCanqSICbxzRNEZGMlu8qfyw"> YouTube channel </a>as well, where one can find a screencast recording of each of the &#8216;musical codes&#8217;. </p>



<div class="wp-block-image"><figure class="aligncenter"><a href="https://www.youtube.com/channel/UCanqSICbxzRNEZGMlu8qfyw" target="_blank" rel="noreferrer noopener"><img src="http://www.michelepasin.org/blog/wp-content/uploads/2021/02/YouTubeMusicalCode-1024x679.jpg" alt="" class="wp-image-3448" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2021/02/YouTubeMusicalCode-1024x679.jpg 1024w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/YouTubeMusicalCode-300x199.jpg 300w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/YouTubeMusicalCode-768x509.jpg 768w, http://www.michelepasin.org/blog/wp-content/uploads/2021/02/YouTubeMusicalCode.jpg 1174w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></figure></div>



<p>Hope someone will find something of interest in there. Comments and feedback totally welcome!</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">3446</post-id>	</item>
		<item>
		<title>Composing at the metalevel</title>
		<link>http://www.michelepasin.org/blog/2012/03/09/composing-at-the-metalevel/</link>
				<comments>http://www.michelepasin.org/blog/2012/03/09/composing-at-the-metalevel/#comments</comments>
				<pubDate>Fri, 09 Mar 2012 12:20:17 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[books]]></category>
		<category><![CDATA[composition]]></category>
		<category><![CDATA[lisp]]></category>
		<category><![CDATA[taube]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=1109</guid>
				<description><![CDATA[I&#8217;ve started reading &#8220;Notes from the Metalevel: An Introduction to Computer Composition&#8220;, by Heinrich Taube, and realised I should have done that a long time ago! Notes From the Metalevel is a practical introduction to computer composition. It is primarily intended for student composers interested in learning how computation can provide them with a new [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I&#8217;ve started reading &#8220;<a href="http://www.routledge.com/books/details/9789026519758/">Notes from the Metalevel: An Introduction to Computer Composition</a>&#8220;, by Heinrich Taube, and realised I should have done that a long time ago! </p>
<p><img src="http://images.tandf.co.uk/common/jackets/weblarge/978902651/9789026519758.jpg" /></p>
<blockquote><p>Notes From the Metalevel is a practical introduction to computer composition. It is primarily intended for student composers interested in learning how computation can provide them with a new paradigm for musical composition.
</p></blockquote>
<p>I happened to have a pdf version of the book, but the good news is that there&#8217;s an <a href="http://www.moz.ac.at/sem/lehre/lib/bib/software/cm/Notes_from_the_Metalevel/index.html">html version of it</a> too, which includes also all the midi files of the numerous examples included in the book. So make sure you check that out, if you&#8217;re interested in computer-based composition. You might also be interested in this <a href="http://www.computermusicjournal.org/reviews/29-3/phillips-taube.html">review on computer music journal</a>, and this <a href="http://camil.music.illinois.edu/Classes/404A1/">course materials</a> from Taube&#8217;s class at Illinois. </p>
<p>The preface to the fist chapter contains this suggestive excerpt from Leonard Schlain&#8217;s book, <em><a href="http://www.alphabetvsgoddess.com/index.html">The Alphabet Versus the Goddess</a></em>, which Taube (page 19-20) uses as a metaphor of what algorithmic composition (i.e., metalevel composition) is::</p>
<blockquote><p>&#8220;<em>The one crowded space in Father Perry&#8217;s house was his bookshelves. I gradually came to understand that the marks on the pages were trapped words. Anyone could learn to decipher the symbols and turn the trapped words loose again into speech. The ink of the print trapped the thoughts; they could no more get away than a doomboo could get out of a pit. When the full realization of what this meant flooded over me, I experienced the same thrill and amazement as when I had my first glimpse of the bright lights of Konakry. I shivered with the intensity of my desire to learn to do this wondrous thing myself.</em>&#8221;<br />
(spoken by Prince Modupe, a west African prince who learned to read as an adult)</p>
<p>It is impossible to know exactly how Prince Modupe felt when he discovered a process by which his very thoughts could be trapped and released at will again into speech. But I think his <strong>epiphany</strong> must be close to what I experienced when, as a young composer, I was first shown how I could <strong>use a computer to represent my musical ideas</strong> and then &#8220;release them&#8221; into musical compositions.<br />
At that instant it became clear to me that there was an <strong>entire level of notation above the scores</strong> that I had been writing in my regular composition classes, a level I knew nothing about! But I could see that in this level it was possible to notate my compositional ideas in a precise manner and work with them in an almost physical way, as &#8220;trapped words&#8221; that could be unleashed into musical sound whenever I wanted.
</p></blockquote>
<p>So what does it meant to compose at the meta level? </p>
<blockquote><p>
Given the existence of the acoustic and score representations one might ask if there is yet another representation that constitutes a level of abstraction above the performance score? The answer, of course, is yes; it is what this book terms the metalevel. If the score represents the composition then <strong>the metalevel represents the composition of the composition</strong>. A metalevel representation of music is concerned with representing the activity, or process, of musical composition as opposed to its artifact, or score.</p>
<p>This book is about <strong>using the computer to instantiate this level</strong>: to define, model and represent the compositional processes, formalism and structures that are articulated in a musical score and acoustic performance but are not literally represented there. By using a computer the composer can work with <strong>an explicit metalevel notation, or language, that makes the metalevel as tangible as the performance and acoustic levels</strong>.
</p></blockquote>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2012/03/09/composing-at-the-metalevel/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">1109</post-id>	</item>
		<item>
		<title>Article: Algorithmic Composition: Computational Thinking in Music</title>
		<link>http://www.michelepasin.org/blog/2011/10/06/article-algorithmic-composition-computational-thinking-in-music/</link>
				<comments>http://www.michelepasin.org/blog/2011/10/06/article-algorithmic-composition-computational-thinking-in-music/#comments</comments>
				<pubDate>Thu, 06 Oct 2011 12:36:51 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[article]]></category>
		<category><![CDATA[ideas]]></category>
		<category><![CDATA[serialism]]></category>

		<guid isPermaLink="false">http://www.michelepasin.org/blog/?p=1069</guid>
				<description><![CDATA[An article by Michael Edwards on algorithmic composition has been published last month on the Communications of the ACM journal. The article is titled Algorithmic Composition: Computational Thinking in Music. Although the article is quite introductory (Edwards makes it clear that the article &#8220;is more illustrative than all-inclusive, presenting examples of particular techniques and some [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>An article by <a href="http://people.ace.ed.ac.uk/staff/medward2/">Michael Edwards</a> on algorithmic composition has been published last month on the Communications of the ACM journal. The article is titled <a href="http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext">Algorithmic Composition: Computational Thinking in Music</a>. </p>
<p>Although the article is quite introductory (Edwards makes it clear that the article &#8220;is more illustrative than all-inclusive, presenting examples of particular techniques and some of the music that has been produced with them&#8221;) it is defintely an interesting read. I found quite a few nice ideas in it and also references to musics and musicians I wasn&#8217;t familiar with. </p>
<p>Follows a list of &#8216;highlights&#8217; from my iPad reader, to which I added hyperlinks to relevant explanatory materials:   </p>
<li>SERIALISM AS A CONTINUATION OF EARLY ALGORITHMIC COMPOSITION</li>
<blockquote><p>After World War II, many Western classical music composers continued to develop the serial technique invented by <a href="http://en.wikipedia.org/wiki/Arnold_Schoenberg">Arnold Schönberg</a> (1874–1951) et al. Though generally seen as a radical break with tradition, in light of the earlier historical examples just presented, <a href="http://en.wikipedia.org/wiki/Serialism">serialism’s</a> detailed organization can be viewed as no more than a continuation of the tradition of formalizing musical composition. Indeed, one of the new generation’s criticisms of Schönberg was that he radicalized only pitch structure, leaving other parameters (such as rhythm, dynamic, even form) in the 19th century. They looked to the music of Schönberg’s pupil <a href="http://en.wikipedia.org/wiki/Anton_Webern">Anton von Webern</a> for inspiration in organizing these other parameters according to serial principles. Hence the rise of the total serialists: <a href="http://en.wikipedia.org/wiki/Pierre_Boulez">Boulez</a>, <a href="http://en.wikipedia.org/wiki/Karlheinz_Stockhausen">Stockhausen</a>, <a href="http://en.wikipedia.org/wiki/Henri_Pousseur">Pousseur</a>, <a href="http://en.wikipedia.org/wiki/Luigi_Nono">Nono</a>, and others in Europe, and <a href="http://en.wikipedia.org/wiki/Milton_Babbitt">Milton Babbitt</a> and his students at Princeton.</p></blockquote>
<li>COMPOSERS: HILLER AND &#8220;THE ILLIAC SUITE FOR STRING QUARTET&#8221;</li>
<blockquote><p><a href="http://en.wikipedia.org/wiki/Lejaren_Hiller">Lejaren Hiller</a> (1924–1994) is widely recognized as the first composer to have applied computer programs to algorithmic composition. The use of specially designed, unique computer hardware was common at U.S. universities in the mid-20th century. Hiller used the Illiac computer at the University of Illinois, Urbana-Champaign, to create experimental new music with algorithms. His collaboration with Leonard Isaacson resulted in 1956 in the first known computer-aided composition, The Illiac Suite for String Quartet (<a href="http://en.wikipedia.org/wiki/Illiac_Suite">wiki</a> | <a href="http://www.youtube.com/watch?v=isvYe6yOPXQ&#038;feature=related">video</a>), programmed in binary, and using, among other techniques, Markov Chains in “random walk” pitch generation algorithms.</p></blockquote>
<li>CAGE ON THE DIFFERENCE BETWEEN TRADITIONAL AND COMPUTER- ASSISTED COMPOSITION</li>
<blockquote><p><a href="http://en.wikipedia.org/wiki/John_Cage">Cage</a> said in an interview during the composition of HPSCHD (<a href="http://en.wikipedia.org/wiki/HPSCHD">wiki</a> | <a href="http://www.youtube.com/watch?v=t_hTxJpWITw">video</a>), &#8220;Formerly, when one worked alone, at a given point a decision was made, and one went in one direction rather than another; whereas, in the case of working with another person and with computer facilities, the need to work as though decisions were scarce—as though you had to limit yourself to one idea—is no longer pressing. It’s a change from the influences of scarcity or economy to the influences of abundance and &#8211; I’d be willing to say—waste.&#8221;
</p></blockquote>
<li>COMPOSERS: XENAKIS</li>
<blockquote><p>Known primarily for his instrumental compositions but also as an engineer and architect, <a href="http://en.wikipedia.org/wiki/Iannis_Xenakis">Iannis Xenakis</a> was a pioneer of algorithmic composition and computer music. Using language typical of the sci-fi age, he wrote, “With the aid of electronic computers, the composer becomes a sort of pilot: he presses buttons, introduces coordinates, and supervises the controls of a cosmic vessel sailing in the space of sound, across sonic constellations and galaxies that he could formerly glimpse only in a distant dream.<br />
[&#8230;]<br />
Xenakis’s approach, which led to the <a href="http://en.wikipedia.org/wiki/Stochastic">Stochastic</a> Music Programme (henceforth SMP) and radically new pieces (such as <a href="http://www.youtube.com/watch?v=sWdQBblec0M">Pithoprakta</a>, 1956), used formulae originally developed by scientists to explain the behavior of gas particles (Maxwell’s and Boltzmann’s Kinetic Theory of Gases). He saw his stochastic compositions as clouds of sound, with individual notes as the analogue of gas particles.<br />
[&#8230;]<br />
His <a href="http://www.youtube.com/watch?v=vbU69HObLeg">Eonta</a> (1963–1964) for two trumpets, three tenor trombones, and piano was composed with SMP. The program was applied in particular to the creation of the massively complex opening piano solo.</p></blockquote>
<li>COMPOSERS: KOENIG</li>
<blockquote><p><a href="http://en.wikipedia.org/wiki/Gottfried_Michael_Koenig">Koenig</a> saw transcription (from computer output to musical score) as an important part of the process of algorithmic composition, writing, &#8220;Neither the histograms nor the connection algorithm contains any hints about the envisaged, ‘unfolded’ score, which consists of instructions for dividing the labor of the production changes mode, that is, the division into performance parts. The histogram, unfolded to reveal the individual time and parameter values, has to be split up into voices.&#8221;
</p></blockquote>
<li>THE CONTEMPORARY LANDSCAPE: A DIVISION BETWEEN COMPOSERS AND AI RESEARCHERS</li>
<blockquote><p>Contemporary (late 20th century) techniques tend to be hybrids of <a href="http://en.wikipedia.org/wiki/Deterministic_algorithm">deterministic</a> and <a href="http://en.wikipedia.org/wiki/Stochastic">stochastic</a> approaches. Systems using techniques from artificial intelligence (AI) and/or linguistics..<br />
[&#8230;]<br />
While naturally significant to AI research, linguistics, and computer science, such systems tend to be of limited use to composers writing music in a modern and personal style that perhaps resists codification because of its notational and sonic complexity and, more simply, its lack of sufficient and stylistically consistent data<br />
[&#8230;]<br />
Thus we can witness a division between composers concerned with creating new music with personalized systems and researchers interested in developing systems for machine learning and AI. The latter may quite understandably find it more useful to generate music in well-known styles not only because there is extant data but also because familiarity of material simplifies some aspects of the assessment of results. Naturally though, more collaboration between composers and researchers could lead to fruitful, aesthetically progressive results.
</p></blockquote>
<li>ALGORITHMIC COMPOSITION OUTSIDE ACADEMIA: BRIAN ENO</li>
<blockquote><p>Application of algorithmic-composition techniques is not restricted to academia or to the classical avant garde. Pop/ambient musician <a href="http://en.wikipedia.org/wiki/Brian_Eno">Brian Eno</a> (1948–) is known for his admiration and use of generative systems in Music for Airports (1978) [<a href="http://en.wikipedia.org/wiki/Ambient_1:_Music_for_Airports">wiki</a> | <a href="http://www.youtube.com/watch?v=B9kPIp4MtX0">video</a>] and other pieces. Eno was inspired by the American <a href="http://en.wikipedia.org/wiki/Minimalist_music">minimalists</a>, in particular <a href="http://en.wikipedia.org/wiki/Steve_Reich">Steve Reich</a> (1936–) and his tape piece It’s Gonna Rain (1965) [<a href="http://en.wikipedia.org/wiki/It's_Gonna_Rain">wiki</a> | <a href="http://www.youtube.com/watch?v=q0DQRfm0uL8">video</a>].<br />
[&#8230;]<br />
Eno said about his Discreet Music (1975) [<a href="http://en.wikipedia.org/wiki/Discreet_Music">wiki</a> | <a href="http://www.youtube.com/watch?v=SrBoE0ItRLc">video</a>], &#8220;Since I have always preferred making plans to executing them, I have gravitated towards situations and systems that, once set into operation, could create music with little or no intervention on my part. That is to say, I tend towards the roles of planner and programmer, and then become an audience to the results&#8221;.</p></blockquote>
<li>LIGETI ON THE RELATION BETWEEN MUSIC AND MATHEMATICS</li>
<blockquote><p>After leaving his native Hungary in the late 1950s, <a href="http://en.wikipedia.org/wiki/Ligeti">Ligeti</a> worked in the same studios as Cologne electronic music pioneers Karlheinz Stockhausen and Gottfried Michael Koenig though produced little electronic music of his own. However, his interest in science and mathematics led to several instrumental pieces influenced by, for example, fractal geometry and chaos theory. But these influences did not lead to a computer-based algorithmic approach. He was quoted in Steinitz saying, &#8220;Somewhere underneath, very deeply, there’s a common place in our spirit where the beauty of mathematics and the beauty of music meet. But they don’t meet on the level of algorithms or making music by calculation. It’s much lower, much deeper—or much higher, you could say.&#8221;
</p></blockquote>
<li>EXAMPLE: AN ALGORITHMIC MODEL OF LIGETI&#8217;S DESORDRE</li>
<blockquote><p>I have implemented algorithmic models of the first part of <a href="http://www.youtube.com/watch?v=qj9QlWltv8s">Désordre</a> in the open-source software system <a href="http://puredata.info/">Pure Data</a>, which, along with the following discussion, is based on analyses by Tobias Kunze,26 used here with permission, and Hartmut Kinzler. It is freely downloadable from my Web site <a href="http://www.michael-edwards.org/software/desordre.zip">http://www.michael-edwards.org/software/desordre.zip</a><br />
[&#8230;]<br />
The main argument of Désordre consists of foreground and background textures..<br />
[&#8230;]<br />
In Désordre we experience a clear, compelling, yet not entirely predictable musical development of rhythmic acceleration coupled with a movement from the middle piano register to the extremes of high and low, all expressed through two related and repeating melodic cycles with slightly differing lengths resulting in a combination that dislocates and leads to metrical disorder. I invite the reader to investigate this in more detail by downloading my software implementation.
</p></blockquote>
<li>ON THE NEGATIVE RECEPTION OF ALGORITHMIC COMPOSITION</li>
<blockquote><p>There has been (and still is) considerable resistance to algorithmic composition from all sides, from musicians to the general public. This resistance bears comparison to the reception of the supposedly overly mathematical serial approach introduced by the composers of the <a href="http://en.wikipedia.org/wiki/Second_Viennese_School">Second Viennese School</a> of the 1920s and 1930s. Alongside the techniques of other music composed from the beginning of the 20th century onward, the serial principle itself is frequently considered to be the reason the music—so-called modern music, though now close to 100 years old — may not appeal.<br />
[&#8230;]<br />
Algorithmic composition is often viewed as a sideline in contemporary musical activity, as opposed to a logical application and incorporation of compositional technique into the digital domain. Without wishing to imply that instrumental composition is in a general state of stagnation, if the computer is the universal tool, there is surely no doubt that not applying it to composition would be, if not exactly an example of Luddism, then at least to risk missing important aesthetic developments that only the computer can facilitate, and that other artistic fields already take advantage of. </p></blockquote>
<li>COMPOSING USING ALGORITHMIC METHODS: MISCONCEPTIONS</li>
<blockquote><p>Much of the resistance to algorithmic composition that persists to this day stems from the misguided bias that the computer, not the composer, composes the music. In the vast majority of cases where the composer is also the programmer, this is simply not true. As composer and computer musician Curtis Roads pointed out more than 15 years ago, it takes a good composer to design algorithms that result in music that captures the imagination.<br />
[&#8230;]<br />
Furthermore, using algorithmic-composition techniques does not by necessity imply less composition work or a shortcut to musical results; rather, it is a change of focus from note-to-note com- position to a top-down formalization of compositional process. Composition is, in fact, often slowed by the requirement that musical ideas be expressed and their characteristics encapsulated in a highly structured and non-musical general programming language. Learning the discipline of programming is itself a time-consuming and, for some composers, an insurmountable problem.</p></blockquote>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>http://www.michelepasin.org/blog/2011/10/06/article-algorithmic-composition-computational-thinking-in-music/feed/</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">1069</post-id>	</item>
		<item>
		<title>New Impromptu screencast and a few lessons learned</title>
		<link>http://www.michelepasin.org/blog/2009/10/07/new-impromptu-screencast/</link>
				<pubDate>Wed, 07 Oct 2009 14:08:43 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[impromptu]]></category>
		<category><![CDATA[livecoding]]></category>

		<guid isPermaLink="false">http://magicrebirth.wordpress.com/?p=353</guid>
				<description><![CDATA[&#8230; Initially this song was called &#8216;Voices Slowly Talk To Me&#8216; &#8211; then.. as usual.. I lost control of its direction! So I don&#8217;t know anymore how much the title would apply. Anyways, it&#8217;s my second experiment with recording an Impromptu performance (by the way I also played it live the other night at the [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><iframe src="http://player.vimeo.com/video/6944991?autoplay=1" width="400" height="327" frameborder="0"></iframe></p>
<p>&#8230;</p>
<p>Initially this song was called &#8216;<strong>Voices Slowly Talk To Me</strong>&#8216; &#8211; then.. as usual.. I lost control of its direction! So I don&#8217;t know anymore how much the title would apply. Anyways, it&#8217;s my second experiment with recording an <a href="http://impromptu.moso.com.au/">Impromptu</a> performance (by the way I also played it live the other night at the <a href="http://www.shunt.co.uk/">Shunt</a> in London, with various mistakes and delays, but somehow I got to the end &#8211; thanks to the <a href="http://toplap.org/uk/">toplap crew</a> for their support!).</p>
<p>Somehow I&#8217;m becoming wiser with doing this type of stuff, you know, just trying to learn from past experiences. So here&#8217;re a few tips I matured in the last weeks:</p>
<ul>
<li><strong>keep it simple</strong>. Especially when playing live. Long and convoluted functions are a giant source of errors especially when you&#8217;re a bit tense</li>
<li><strong>use &#8216;paste&#8217; templates</strong>. Stuff like the <em>pb:cb </em>function that comes by default with Impromptu.  At the beginning I thought it wouldn&#8217;t look too good, cause you&#8217;ve gotta show that you&#8217;re coding the whole thing from scratch. But actually, <strong>when you&#8217;re livecoding </strong> time is very very precious and what you want to focus on is <strong>sound, primarily</strong> (well at least this is what I like to do). It&#8217;s also important to remember that many other environments for live performance are much much <em>higher level</em> than Impromptu &#8211; meaning that it&#8217;s quicker to emit sounds or musical structures and change their properties&#8230; so let&#8217;s make sure we&#8217;re not comparing apple and oranges here! </li>
<li><strong>make variations often</strong>. Even if they look stupid to you, change something, add another melody, double the drumkit, stuff like that. The audience  is more interested in new audio-visual things happening that in seeing you code a Bach&#8217;s prelude.</li>
<li><strong>exercise a lot</strong>. I initially felt weird about this, mainly because playing with Impromptu means coding, and when I code I usually take my time and think. But livecoding transforms the coding practice into a musical performance. Which means that you don&#8217;t have time to think, <strong>things should just come out automatically and sound good.</strong> Only then you can take the freedom of &#8216;jamming&#8217; without a plan. I play guitar, and that&#8217;s exactly how it works there&#8230; I must have forgotten about it. When playing a song I can&#8217;t lose time trying to remember how to lay out the fingers on the neck, that has to happen automatically.</li>
</ul>
<p>That&#8217;s it for now &#8211; I&#8217;ll touch base again about this when the next live coding performance will happen! Rock on live-coders!</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">353</post-id>	</item>
		<item>
		<title>Algorithmic music: exercise #1</title>
		<link>http://www.michelepasin.org/blog/2009/06/23/algorithmic-music-exercise-1/</link>
				<pubDate>Tue, 23 Jun 2009 10:12:09 +0000</pubDate>
		<dc:creator><![CDATA[mikele]]></dc:creator>
				<category><![CDATA[Computer Music]]></category>
		<category><![CDATA[algorithmiccomposition]]></category>
		<category><![CDATA[impromptu]]></category>

		<guid isPermaLink="false">http://magicrebirth.wordpress.com/?p=221</guid>
				<description><![CDATA[&#8230; I finally managed to find time to play more seriously with the fantastic impromptu &#8211; here&#8217;s a first screencast, it doesn&#8217;t sound that good but it made my day! (and maybe it&#8217;ll help others better understand how impromptu works..) p.s. I&#8217;m intending to start posting more stuff about impromptu (e.g. little libraries and code [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><a href="http://www.vimeo.com/5283639"><img src="http://magicrebirth.webfactional.com/blog/wp-content/uploads/2009/06/picture-16.png" alt="Picture 1" title="Picture 1" width="501" height="363" class="alignnone size-full wp-image-223" srcset="http://www.michelepasin.org/blog/wp-content/uploads/2009/06/picture-16.png 501w, http://www.michelepasin.org/blog/wp-content/uploads/2009/06/picture-16-300x217.png 300w" sizes="(max-width: 501px) 100vw, 501px" /></a><br />
&#8230;</p>
<p>I finally managed to find time to play more seriously with the fantastic <a href="http://impromptu.moso.com.au/">impromptu</a> &#8211; here&#8217;s a first <strong>screencast</strong>, it doesn&#8217;t sound <em>that</em> good but it made my day! (and maybe it&#8217;ll help others better understand how impromptu works..)</p>
<p>p.s.<br />
I&#8217;m intending to start posting more stuff about impromptu (e.g. little libraries and code samples), stay tuned!</p>
]]></content:encoded>
									<post-id xmlns="com-wordpress:feed-additions:1">221</post-id>	</item>
	</channel>
</rss>
